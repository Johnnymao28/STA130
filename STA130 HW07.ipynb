{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5fff0fd",
   "metadata": {},
   "source": [
    "# Pre-lecture HW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dabff8",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48b1c0b",
   "metadata": {},
   "source": [
    "## 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffe498a",
   "metadata": {},
   "source": [
    "### Simple Linear Regression uses a single predictor variable to predict the outcome. Its form is: outcome = intercept + slope*predictor  where outcome is the result, intercept is the intercept term, slope is the coefficient for the predictor variable, and predictor is the variable used for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476e4188",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression uses multiple predictor variables together to predict the outcome. Its form is: outcome = intercept + slope1*predictor1 + slope2*predictor2 + ... + slopeN*predictorN By introducing multiple predictors (predictor1, predictor2, ..., predictorN), Multiple Linear Regression can capture more complex relationships and improve the model’s predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6109aae6",
   "metadata": {},
   "source": [
    "### Compared to Simple Linear Regression, Multiple Linear Regression introduces multiple predictor variables, allowing it to explain complex relationships caused by multiple factors and to make more accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b9488b",
   "metadata": {},
   "source": [
    "## 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7c230b",
   "metadata": {},
   "source": [
    "### Continuous Variable: In Simple Linear Regression, when using a continuous variable, the formula is: outcome = intercept + slope * predictor  Here, predictor is a continuous variable, meaning its effect on the outcome changes linearly with its value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7df29cb",
   "metadata": {},
   "source": [
    "### Indicator Variable: An indicator variable is used to represent categorical factors and is typically a binary variable, indicating whether or not it belongs to a certain category. Its form is: outcome = intercept + slope * 1(predictorB)  Here, 1(predictorB) is the indicator variable, taking a value of 1 when a certain condition is met (for example, when predictorB is “yes”) and 0 otherwise. This allows the model to capture the influence of different categories on the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8599516e",
   "metadata": {},
   "source": [
    "## 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff55e0",
   "metadata": {},
   "source": [
    "### When an indicator variable and a continuous variable are introduced in Multiple Linear Regression, the behavior of the model changes, allowing the outcome to vary based on the category represented by the indicator variable. This model can capture not only the influence of the continuous variable but also the differences between categories, making the model more flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba32d2d7",
   "metadata": {},
   "source": [
    "### When the indicator variable is added, the model becomes outcome = intercept + slopeA*predictorA + slopeB*1(predictorB). Here, 1(predictorB) is an indicator variable that takes a value of 1 when a certain condition is met and 0 otherwise. slopeB * 1(predictorB) adjusts the baseline outcome depending on whether the indicator variable is 0 or 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724aa491",
   "metadata": {},
   "source": [
    "### The effect of introducing this variable is that when 1(predictorB) = 0, the model behaves like a Simple Linear Regression: outcome = intercept + slopeA*predictorA. When 1(predictorB) = 1, the outcome is adjusted by slopeB, so the formula becomes: outcome = (intercept + slopeB) + slopeA*predictorA. This approach allows the model to capture differences between categories while still considering the influence of the continuous variable. The model now expects the outcome to have different baseline levels across categories, better reflecting the characteristics of the data within each category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53452ad1",
   "metadata": {},
   "source": [
    "## 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eb24d4",
   "metadata": {},
   "source": [
    "### In Multiple Linear Regression, adding an interaction term between a continuous variable and an indicator variable allows the model to capture whether the effect of the continuous variable on the outcome changes based on the category of the indicator variable. In other words, the interaction term can reflect differences in the relationship between the continuous variable and the outcome across different categories. By introducing the interaction term, the model can adjust the effect of the continuous variable according to the category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6ed059",
   "metadata": {},
   "source": [
    "### Without an interaction term: outcome = intercept + slopeA*predictorA + slopeB*1(predictorB). In this case, the effects of predictorA (the continuous variable) and 1(predictorB) (the indicator variable) are independent of each other, meaning the effect of predictorA on the outcome does not vary based on the category of predictorB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e4775d",
   "metadata": {},
   "source": [
    "### With an interaction term: outcome = intercept + slopeA*predictorA + slopeB*1(predictorB) + slopeInteraction*predictorA*1(predictorB). Here, slopeInteraction*predictorA*1(predictorB) is the interaction term, indicating that the effect of predictorA on the outcome varies based on the category of predictorB (0 or 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cad7e37",
   "metadata": {},
   "source": [
    "## 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee93fc4",
   "metadata": {},
   "source": [
    "### In Multiple Linear Regression, if the model is based only on indicator variables derived from a non-binary categorical variable, it can capture the differences between multiple categories. To avoid multicollinearity, one of the categories is chosen as the baseline category, and the outcome for the baseline is typically represented by the model's intercept term. This approach allows the model to express each category’s outcome relative to the baseline category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a2e2e8",
   "metadata": {},
   "source": [
    "### Suppose there is a categorical variable with three categories: A, B, and C. To represent this variable in a regression model, we create indicator variables for two of the categories, while the third category (e.g., C) is used as the baseline. The model is represented as:outcome = intercept + slopeA*1(category = A) + slopeB*1(category = B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bb8425",
   "metadata": {},
   "source": [
    "### In this model: 1(category = A) and 1(category = B) are indicator variables that take the value of 1 when the category is A or B, respectively, and 0 otherwise. slopeA and slopeB represent the effects of categories A and B relative to the baseline category C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8004432a",
   "metadata": {},
   "source": [
    "### Since we have not set an indicator variable for category C, when the category is C, both 1(category = A) and 1(category = B) are equal to 0, and the model simplifies to: outcome = intercept. This means that the intercept represents the expected outcome for the baseline category C. Relative to the baseline category C, the outcomes for categories A and B are intercept + slopeA and intercept + slopeB, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ce3f1f",
   "metadata": {},
   "source": [
    "### Choosing a baseline category (e.g., C) simplifies the model and ensures that it avoids multicollinearity due to redundant indicator variables. The baseline category provides a reference point for the model, allowing it to interpret variations or deviations of other categories relative to it. This way, each category's coefficient represents the increase or decrease in outcome relative to the baseline, clearly reflecting the relative effects of different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e21d624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Indicator Variables:\n",
      "- When an indicator (dummy) variable is used in MLR, it allows the model to have different intercepts for each category.\n",
      "- The slope remains the same across categories, capturing baseline differences between groups.\n",
      "\n",
      "2. Interaction Between Continuous and Indicator Variables:\n",
      "- Adding an interaction term between a continuous variable and an indicator variable allows each category to have its own slope.\n",
      "- This makes the model capable of capturing group-specific effects on the dependent variable.\n",
      "\n",
      "3. Model with Only Indicator Variables:\n",
      "- MLR models based solely on indicator variables (dummy variables) from non-binary categorical data create separate group means.\n",
      "- Binary encoding is used for each category, with one category as a reference.\n",
      "- This encoding allows the model to assess differences between each category and the reference category without continuous relationships.\n",
      "\n",
      "Summary:\n",
      "- MLR with indicator variables and interaction terms extends the model’s flexibility, capturing both categorical and continuous relationships.\n",
      "- Indicator variables help model group-specific baselines, and interaction terms allow category-specific slopes for continuous variables.\n"
     ]
    }
   ],
   "source": [
    "# Chat Summary\n",
    "\n",
    "print(\"1. Indicator Variables:\")\n",
    "print(\"- When an indicator (dummy) variable is used in MLR, it allows the model to have different intercepts for each category.\")\n",
    "print(\"- The slope remains the same across categories, capturing baseline differences between groups.\\n\")\n",
    "\n",
    "print(\"2. Interaction Between Continuous and Indicator Variables:\")\n",
    "print(\"- Adding an interaction term between a continuous variable and an indicator variable allows each category to have its own slope.\")\n",
    "print(\"- This makes the model capable of capturing group-specific effects on the dependent variable.\\n\")\n",
    "\n",
    "print(\"3. Model with Only Indicator Variables:\")\n",
    "print(\"- MLR models based solely on indicator variables (dummy variables) from non-binary categorical data create separate group means.\")\n",
    "print(\"- Binary encoding is used for each category, with one category as a reference.\")\n",
    "print(\"- This encoding allows the model to assess differences between each category and the reference category without continuous relationships.\\n\")\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(\"- MLR with indicator variables and interaction terms extends the model’s flexibility, capturing both categorical and continuous relationships.\")\n",
    "print(\"- Indicator variables help model group-specific baselines, and interaction terms allow category-specific slopes for continuous variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0698295e",
   "metadata": {},
   "source": [
    "link with ChatGPT: https://chatgpt.com/share/6735ac37-d9c8-800d-a714-96bc859d91c9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ced677f",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad3d14a",
   "metadata": {},
   "source": [
    "## 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b22a2",
   "metadata": {},
   "source": [
    "### Outcome Variable: Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b176b8",
   "metadata": {},
   "source": [
    "### Predictor Variables: TV advertising budget and online advertising budget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7ca9eb",
   "metadata": {},
   "source": [
    "### An interaction effect should be considered because the impact of TV advertising may vary depending on the level of investment in online advertising."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8113071e",
   "metadata": {},
   "source": [
    "### Without Interaction: Sales = beta0 + betaTV*TV + betaOnline*Online  With Interaction: Sales = beta0 + betaTV*TV + betaOnline*Online + betaTV_Online*(TV*Online)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f6ac8c",
   "metadata": {},
   "source": [
    "### With Interaction: Sales = beta0 + betaTV*TV + betaOnline*Online + betaTV_Online*(TV*Online)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071b8f5f",
   "metadata": {},
   "source": [
    "### Without Interaction: The effects of TV and online advertising on sales are independent.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b14917",
   "metadata": {},
   "source": [
    "### With Interaction: The combined effect of both types of advertising on sales is greater than the sum of their individual effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c38acd",
   "metadata": {},
   "source": [
    "## 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1e91ed",
   "metadata": {},
   "source": [
    "### Define binary variables TV and Online, where a \"high\" budget is coded as 1 and a \"low\" budget is coded as 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a0a149",
   "metadata": {},
   "source": [
    "### Model Without Interaction: Sales = beta0 + betaTV*TV + betaOnline*Online  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b6603d",
   "metadata": {},
   "source": [
    "### Model With Interaction: Sales = beta0 + betaTV*TV + betaOnline*Online + betaTV_Online*(TV*Online)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d17e745",
   "metadata": {},
   "source": [
    "### Model Without Interaction: The effect of each advertising budget on sales is independent; the impact of a \"high\" budget on sales is unaffected by the budget level of the other type of advertising."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf4a3f7",
   "metadata": {},
   "source": [
    "### Model With Interaction: When both TV and online advertising budgets are \"high,\" there is an additional synergistic effect, causing sales to increase beyond the simple independent effects of each budget. This model is appropriate when combined advertising budgets have an extra influence on sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b22c09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We explored how to model the effect of advertising on sales for a sports equipment company,\n",
      "specifically considering TV and online advertising.\n",
      "We discussed two models:\n",
      "\n",
      "1. Model without Interaction:\n",
      "This model assumes each advertising medium (TV and online) independently affects sales.\n",
      "We simply add their contributions, meaning that the effect of TV ads on sales is constant regardless of online ad spending and vice versa.\n",
      "\n",
      "2. Model with Interaction:\n",
      "This model includes an interaction term to account for a combined effect of TV and online advertising,\n",
      "where the impact of one ad medium depends on the spending level of the other.\n",
      "For instance, a high budget for online ads could make TV ads more effective.\n",
      "\n",
      "We then adapted these models for a scenario where advertising budgets are classified as 'high' or 'low' (binary variables).\n",
      "For binary models:\n",
      "\n",
      "- Without Interaction:\n",
      "Predicts sales based on independent effects of 'high' or 'low' budgets for each medium.\n",
      "\n",
      "- With Interaction:\n",
      "Includes a term to capture the synergy between high TV and high online budgets,\n",
      "which could result in a greater effect on sales than the independent effects combined.\n"
     ]
    }
   ],
   "source": [
    "# Chat Summary\n",
    "\n",
    "print(\"We explored how to model the effect of advertising on sales for a sports equipment company,\")\n",
    "print(\"specifically considering TV and online advertising.\")\n",
    "print(\"We discussed two models:\")\n",
    "\n",
    "print(\"\\n1. Model without Interaction:\")\n",
    "print(\"This model assumes each advertising medium (TV and online) independently affects sales.\")\n",
    "print(\"We simply add their contributions, meaning that the effect of TV ads on sales is constant regardless of online ad spending and vice versa.\")\n",
    "\n",
    "print(\"\\n2. Model with Interaction:\")\n",
    "print(\"This model includes an interaction term to account for a combined effect of TV and online advertising,\")\n",
    "print(\"where the impact of one ad medium depends on the spending level of the other.\")\n",
    "print(\"For instance, a high budget for online ads could make TV ads more effective.\")\n",
    "\n",
    "print(\"\\nWe then adapted these models for a scenario where advertising budgets are classified as 'high' or 'low' (binary variables).\")\n",
    "print(\"For binary models:\")\n",
    "\n",
    "print(\"\\n- Without Interaction:\")\n",
    "print(\"Predicts sales based on independent effects of 'high' or 'low' budgets for each medium.\")\n",
    "\n",
    "print(\"\\n- With Interaction:\")\n",
    "print(\"Includes a term to capture the synergy between high TV and high online budgets,\")\n",
    "print(\"which could result in a greater effect on sales than the independent effects combined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03961f6d",
   "metadata": {},
   "source": [
    "link with ChatGPT: https://chatgpt.com/share/67365796-a96c-800d-907d-a4c6a3d37c24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df215b6",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3bec74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.228109\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>str8fyre</td>     <th>  No. Observations:  </th>  <td>   800</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   788</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    11</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 14 Nov 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.05156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>20:34:52</td>     <th>  Log-Likelihood:    </th> <td> -182.49</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -192.41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td>0.04757</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                      <td></td>                        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                <td>   -3.2644</td> <td>    0.714</td> <td>   -4.572</td> <td> 0.000</td> <td>   -4.664</td> <td>   -1.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>                        <td>    4.3478</td> <td>    2.179</td> <td>    1.996</td> <td> 0.046</td> <td>    0.078</td> <td>    8.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 2\") == \"None\")[T.True]</th>         <td>    1.5432</td> <td>    0.853</td> <td>    1.810</td> <td> 0.070</td> <td>   -0.128</td> <td>    3.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>                       <td>   -0.0574</td> <td>    0.468</td> <td>   -0.123</td> <td> 0.902</td> <td>   -0.975</td> <td>    0.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>                       <td>   -0.6480</td> <td>    0.466</td> <td>   -1.390</td> <td> 0.164</td> <td>   -1.561</td> <td>    0.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>                       <td>   -0.8255</td> <td>    0.545</td> <td>   -1.516</td> <td> 0.130</td> <td>   -1.893</td> <td>    0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>                       <td>   -0.5375</td> <td>    0.449</td> <td>   -1.198</td> <td> 0.231</td> <td>   -1.417</td> <td>    0.342</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>                       <td>    0.3213</td> <td>    0.477</td> <td>    0.673</td> <td> 0.501</td> <td>   -0.614</td> <td>    1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                   <td>    0.0172</td> <td>    0.006</td> <td>    3.086</td> <td> 0.002</td> <td>    0.006</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]</th>                 <td>   -0.0365</td> <td>    0.019</td> <td>   -1.884</td> <td> 0.060</td> <td>   -0.074</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                                  <td>   -0.0098</td> <td>    0.008</td> <td>   -1.247</td> <td> 0.213</td> <td>   -0.025</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:I(Q(\"Type 2\") == \"None\")[T.True]</th> <td>   -0.0197</td> <td>    0.012</td> <td>   -1.651</td> <td> 0.099</td> <td>   -0.043</td> <td>    0.004</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                           &     str8fyre     & \\textbf{  No. Observations:  } &      800    \\\\\n",
       "\\textbf{Model:}                                   &      Logit       & \\textbf{  Df Residuals:      } &      788    \\\\\n",
       "\\textbf{Method:}                                  &       MLE        & \\textbf{  Df Model:          } &       11    \\\\\n",
       "\\textbf{Date:}                                    & Thu, 14 Nov 2024 & \\textbf{  Pseudo R-squ.:     } &  0.05156    \\\\\n",
       "\\textbf{Time:}                                    &     20:34:52     & \\textbf{  Log-Likelihood:    } &   -182.49   \\\\\n",
       "\\textbf{converged:}                               &       True       & \\textbf{  LL-Null:           } &   -192.41   \\\\\n",
       "\\textbf{Covariance Type:}                         &    nonrobust     & \\textbf{  LLR p-value:       } &  0.04757    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                  & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                &      -3.2644  &        0.714     &    -4.572  &         0.000        &       -4.664    &       -1.865     \\\\\n",
       "\\textbf{Legendary[T.True]}                        &       4.3478  &        2.179     &     1.996  &         0.046        &        0.078    &        8.618     \\\\\n",
       "\\textbf{I(Q(\"Type 2\") == \"None\")[T.True]}         &       1.5432  &        0.853     &     1.810  &         0.070        &       -0.128    &        3.215     \\\\\n",
       "\\textbf{C(Generation)[T.2]}                       &      -0.0574  &        0.468     &    -0.123  &         0.902        &       -0.975    &        0.861     \\\\\n",
       "\\textbf{C(Generation)[T.3]}                       &      -0.6480  &        0.466     &    -1.390  &         0.164        &       -1.561    &        0.265     \\\\\n",
       "\\textbf{C(Generation)[T.4]}                       &      -0.8255  &        0.545     &    -1.516  &         0.130        &       -1.893    &        0.242     \\\\\n",
       "\\textbf{C(Generation)[T.5]}                       &      -0.5375  &        0.449     &    -1.198  &         0.231        &       -1.417    &        0.342     \\\\\n",
       "\\textbf{C(Generation)[T.6]}                       &       0.3213  &        0.477     &     0.673  &         0.501        &       -0.614    &        1.257     \\\\\n",
       "\\textbf{Attack}                                   &       0.0172  &        0.006     &     3.086  &         0.002        &        0.006    &        0.028     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]}                 &      -0.0365  &        0.019     &    -1.884  &         0.060        &       -0.074    &        0.001     \\\\\n",
       "\\textbf{Defense}                                  &      -0.0098  &        0.008     &    -1.247  &         0.213        &       -0.025    &        0.006     \\\\\n",
       "\\textbf{Defense:I(Q(\"Type 2\") == \"None\")[T.True]} &      -0.0197  &        0.012     &    -1.651  &         0.099        &       -0.043    &        0.004     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               str8fyre   No. Observations:                  800\n",
       "Model:                          Logit   Df Residuals:                      788\n",
       "Method:                           MLE   Df Model:                           11\n",
       "Date:                Thu, 14 Nov 2024   Pseudo R-squ.:                 0.05156\n",
       "Time:                        20:34:52   Log-Likelihood:                -182.49\n",
       "converged:                       True   LL-Null:                       -192.41\n",
       "Covariance Type:            nonrobust   LLR p-value:                   0.04757\n",
       "============================================================================================================\n",
       "                                               coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                   -3.2644      0.714     -4.572      0.000      -4.664      -1.865\n",
       "Legendary[T.True]                            4.3478      2.179      1.996      0.046       0.078       8.618\n",
       "I(Q(\"Type 2\") == \"None\")[T.True]             1.5432      0.853      1.810      0.070      -0.128       3.215\n",
       "C(Generation)[T.2]                          -0.0574      0.468     -0.123      0.902      -0.975       0.861\n",
       "C(Generation)[T.3]                          -0.6480      0.466     -1.390      0.164      -1.561       0.265\n",
       "C(Generation)[T.4]                          -0.8255      0.545     -1.516      0.130      -1.893       0.242\n",
       "C(Generation)[T.5]                          -0.5375      0.449     -1.198      0.231      -1.417       0.342\n",
       "C(Generation)[T.6]                           0.3213      0.477      0.673      0.501      -0.614       1.257\n",
       "Attack                                       0.0172      0.006      3.086      0.002       0.006       0.028\n",
       "Attack:Legendary[T.True]                    -0.0365      0.019     -1.884      0.060      -0.074       0.001\n",
       "Defense                                     -0.0098      0.008     -1.247      0.213      -0.025       0.006\n",
       "Defense:I(Q(\"Type 2\") == \"None\")[T.True]    -0.0197      0.012     -1.651      0.099      -0.043       0.004\n",
       "============================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "pokeaman = pd.read_csv(url).fillna('None')\n",
    "\n",
    "pokeaman['str8fyre'] = (pokeaman['Type 1']=='Fire').astype(int)\n",
    "linear_model_specification_formula = \\\n",
    "'str8fyre ~ Attack*Legendary + Defense*I(Q(\"Type 2\")==\"None\") + C(Generation)'\n",
    "log_reg_fit = smf.logit(linear_model_specification_formula, data=pokeaman).fit()\n",
    "log_reg_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db51b08b",
   "metadata": {},
   "source": [
    "## 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db715bce",
   "metadata": {},
   "source": [
    "### Additive Model: Each predictor variable’s coefficient represents its independent effect on the outcome. For example, if 'binary_var1' is 1, the predicted outcome will increase or decrease according to the coefficient of this variable, assuming all other variables remain constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dccfb63",
   "metadata": {},
   "source": [
    "### Synergistic Interaction Model: The interaction term's coefficient shows how the effect of one predictor depends on the value of another predictor. For example, the interaction term 'continuous_var1 * binary_var1' indicates how the value of 'binary_var1' changes the effect of 'continuous_var1' on the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a551afb9",
   "metadata": {},
   "source": [
    "## 3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1580daf",
   "metadata": {},
   "source": [
    "### Use the '.fit().summary()' output table to examine the p-value of each predictor variable to determine whether it has a significant effect on the outcome variable. When the p-value is less than 0.05, the variable is considered statistically significant and likely to influence the predicted outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7840882",
   "metadata": {},
   "source": [
    "## 3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9efe2b",
   "metadata": {},
   "source": [
    "### Generate random data for a continuous predictor and a binary predictor.  Assume this data follows a multivariate linear regression structure, allowing us to plot the \"best fit line.\" Fit two \"hypothetical\" linear regression models: one for the additive model and one for the interaction (synergistic) effect model, using the same formula structure as in logistic regression. Visualize the best fit lines for both models. For the additive model, plot the line representing the independent effects of each predictor variable. For the synergistic model, add the interaction term and visualize how it affects the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c35a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Step 1: Simulate data\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "X = np.random.uniform(0, 10, n)  # Continuous predictor\n",
    "Z = np.random.choice([0, 1], n)   # Binary predictor\n",
    "noise = np.random.normal(0, 1, n) # Random noise\n",
    "\n",
    "# Define true parameters for the model\n",
    "beta0 = 2    # Intercept\n",
    "beta1 = 0.5  # Coefficient for X\n",
    "beta2 = 1.5  # Coefficient for Z (binary variable)\n",
    "beta3 = 0.7  # Interaction term (for synergistic model)\n",
    "\n",
    "# Generate outcome variable Y for both additive and interaction models\n",
    "Y_additive = beta0 + beta1 * X + beta2 * Z + noise\n",
    "Y_interaction = beta0 + beta1 * X + beta2 * Z + beta3 * X * Z + noise\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'X': X, 'Z': Z, 'Y_additive': Y_additive, 'Y_interaction': Y_interaction})\n",
    "\n",
    "# Step 2: Fit models\n",
    "# Additive model: Y ~ X + Z\n",
    "model_additive = smf.ols('Y_additive ~ X + Z', data=df).fit()\n",
    "\n",
    "# Interaction model: Y ~ X + Z + X:Z\n",
    "model_interaction = smf.ols('Y_interaction ~ X + Z + X:Z', data=df).fit()\n",
    "\n",
    "# Step 3: Plot the models\n",
    "# Additive Model Plot\n",
    "fig_additive = px.scatter(df, x='X', y='Y_additive', color='Z', \n",
    "                          title=\"Additive Model: Y ~ X + Z\",\n",
    "                          labels={'X': 'Continuous Predictor (X)', 'Y_additive': 'Response (Y)'})\n",
    "# Add line of best fit for the additive model\n",
    "X_line = np.linspace(0, 10, 100)\n",
    "for z_val in [0, 1]:  # Plot for each level of Z\n",
    "    Y_line = model_additive.params['Intercept'] + model_additive.params['X'] * X_line + model_additive.params['Z'] * z_val\n",
    "    fig_additive.add_scatter(x=X_line, y=Y_line, mode='lines', name=f'Z={z_val} (Additive)')\n",
    "\n",
    "# Interaction Model Plot\n",
    "fig_interaction = px.scatter(df, x='X', y='Y_interaction', color='Z', \n",
    "                             title=\"Interaction Model: Y ~ X + Z + X:Z\",\n",
    "                             labels={'X': 'Continuous Predictor (X)', 'Y_interaction': 'Response (Y)'})\n",
    "# Add line of best fit for the interaction model\n",
    "for z_val in [0, 1]:  # Plot for each level of Z with interaction\n",
    "    Y_line = (model_interaction.params['Intercept'] \n",
    "              + model_interaction.params['X'] * X_line \n",
    "              + model_interaction.params['Z'] * z_val \n",
    "              + model_interaction.params['X:Z'] * X_line * z_val)\n",
    "    fig_interaction.add_scatter(x=X_line, y=Y_line, mode='lines', name=f'Z={z_val} (Interaction)')\n",
    "\n",
    "# Display the plots\n",
    "fig_additive.show(renderer=\"png\")\n",
    "fig_interaction.show(renderer=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42bb121b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 'Interpreting Logistic Regression as Linear Regression', 'details': ['The code provided simulates data for a continuous predictor (X), a binary predictor (Z), and response variables (Y_additive and Y_interaction) with noise.', 'Two models were fit: an additive model (Y ~ X + Z) and an interaction model (Y ~ X + Z + X:Z).', 'Plotly was used to plot the models separately, assessing if the interaction term significantly changes the model’s fit.'], '2': 'Visualizing Data with Plotly', '3': 'Python Code for Visualization'}\n"
     ]
    }
   ],
   "source": [
    "#Chat Summary\n",
    "\n",
    "summary = {\n",
    "    \"1\": \"Interpreting Logistic Regression as Linear Regression\",\n",
    "    \"details\": [\n",
    "        \"Discussed interpreting logistic regression models as if they were multivariate linear regression models.\",\n",
    "        \"This approach treats coefficients as indicating the relative impact on the dependent variable.\",\n",
    "        \"Focus is on p-values and confidence intervals from `.fit().summary()` for easier interpretation.\"\n",
    "    ],\n",
    "    \n",
    "    \"2\": \"Visualizing Data with Plotly\",\n",
    "    \"details\": [\n",
    "        \"Explored creating visualizations to compare additive and interaction (synergistic) models.\",\n",
    "        \"The additive model assumes no interaction between predictors.\",\n",
    "        \"The interaction model includes a term for the combined effect of the continuous and binary predictors.\"\n",
    "    ],\n",
    "\n",
    "    \"3\": \"Python Code for Visualization\",\n",
    "    \"details\": [\n",
    "        \"The code provided simulates data for a continuous predictor (X), a binary predictor (Z), and response variables (Y_additive and Y_interaction) with noise.\",\n",
    "        \"Two models were fit: an additive model (Y ~ X + Z) and an interaction model (Y ~ X + Z + X:Z).\",\n",
    "        \"Plotly was used to plot the models separately, assessing if the interaction term significantly changes the model’s fit.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7578797",
   "metadata": {},
   "source": [
    "link with ChatGPT: https://chatgpt.com/share/673664b4-e6b8-800d-9e99-42bc75119d57"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86999af5",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3739015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>719</td>\n",
       "      <td>Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>719</td>\n",
       "      <td>DiancieMega Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Unbound</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Dark</td>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>170</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>721</td>\n",
       "      <td>Volcanion</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Water</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>120</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                   Name   Type 1  Type 2  HP  Attack  Defense  \\\n",
       "0      1              Bulbasaur    Grass  Poison  45      49       49   \n",
       "1      2                Ivysaur    Grass  Poison  60      62       63   \n",
       "2      3               Venusaur    Grass  Poison  80      82       83   \n",
       "3      3  VenusaurMega Venusaur    Grass  Poison  80     100      123   \n",
       "4      4             Charmander     Fire     NaN  39      52       43   \n",
       "..   ...                    ...      ...     ...  ..     ...      ...   \n",
       "795  719                Diancie     Rock   Fairy  50     100      150   \n",
       "796  719    DiancieMega Diancie     Rock   Fairy  50     160      110   \n",
       "797  720    HoopaHoopa Confined  Psychic   Ghost  80     110       60   \n",
       "798  720     HoopaHoopa Unbound  Psychic    Dark  80     160       60   \n",
       "799  721              Volcanion     Fire   Water  80     110      120   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0         65       65     45           1      False  \n",
       "1         80       80     60           1      False  \n",
       "2        100      100     80           1      False  \n",
       "3        122      120     80           1      False  \n",
       "4         60       50     65           1      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "795      100      150     50           6       True  \n",
       "796      160      110    110           6       True  \n",
       "797      150      130     70           6       True  \n",
       "798      170      130     80           6       True  \n",
       "799      130       90     70           6       True  \n",
       "\n",
       "[800 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "# fail https://github.com/KeithGalli/pandas/blob/master/pokemon_data.csv\n",
    "pokeaman = pd.read_csv(url) \n",
    "pokeaman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53696a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>3.50e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:59:51</td>     <th>  Log-Likelihood:    </th> <td> -3649.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   800</td>      <th>  AIC:               </th> <td>   7323.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   788</td>      <th>  BIC:               </th> <td>   7379.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                       <td>   26.8971</td> <td>    5.246</td> <td>    5.127</td> <td> 0.000</td> <td>   16.599</td> <td>   37.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>              <td>   20.0449</td> <td>    7.821</td> <td>    2.563</td> <td> 0.011</td> <td>    4.692</td> <td>   35.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>              <td>   21.3662</td> <td>    6.998</td> <td>    3.053</td> <td> 0.002</td> <td>    7.629</td> <td>   35.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>              <td>   31.9575</td> <td>    8.235</td> <td>    3.881</td> <td> 0.000</td> <td>   15.793</td> <td>   48.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>              <td>    9.4926</td> <td>    7.883</td> <td>    1.204</td> <td> 0.229</td> <td>   -5.982</td> <td>   24.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>              <td>   22.2693</td> <td>    8.709</td> <td>    2.557</td> <td> 0.011</td> <td>    5.173</td> <td>   39.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                    <td>    0.5634</td> <td>    0.071</td> <td>    7.906</td> <td> 0.000</td> <td>    0.423</td> <td>    0.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.2]</th> <td>   -0.2350</td> <td>    0.101</td> <td>   -2.316</td> <td> 0.021</td> <td>   -0.434</td> <td>   -0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.3]</th> <td>   -0.3067</td> <td>    0.093</td> <td>   -3.300</td> <td> 0.001</td> <td>   -0.489</td> <td>   -0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.4]</th> <td>   -0.3790</td> <td>    0.105</td> <td>   -3.600</td> <td> 0.000</td> <td>   -0.586</td> <td>   -0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.5]</th> <td>   -0.0484</td> <td>    0.108</td> <td>   -0.447</td> <td> 0.655</td> <td>   -0.261</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.6]</th> <td>   -0.3083</td> <td>    0.112</td> <td>   -2.756</td> <td> 0.006</td> <td>   -0.528</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>337.229</td> <th>  Durbin-Watson:     </th> <td>   1.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2871.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.684</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>11.649</td>  <th>  Cond. No.          </th> <td>1.40e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                  &        HP        & \\textbf{  R-squared:         } &     0.176   \\\\\n",
       "\\textbf{Model:}                          &       OLS        & \\textbf{  Adj. R-squared:    } &     0.164   \\\\\n",
       "\\textbf{Method:}                         &  Least Squares   & \\textbf{  F-statistic:       } &     15.27   \\\\\n",
       "\\textbf{Date:}                           & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  3.50e-27   \\\\\n",
       "\\textbf{Time:}                           &     21:59:51     & \\textbf{  Log-Likelihood:    } &   -3649.4   \\\\\n",
       "\\textbf{No. Observations:}               &         800      & \\textbf{  AIC:               } &     7323.   \\\\\n",
       "\\textbf{Df Residuals:}                   &         788      & \\textbf{  BIC:               } &     7379.   \\\\\n",
       "\\textbf{Df Model:}                       &          11      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                         & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                       &      26.8971  &        5.246     &     5.127  &         0.000        &       16.599    &       37.195     \\\\\n",
       "\\textbf{C(Generation)[T.2]}              &      20.0449  &        7.821     &     2.563  &         0.011        &        4.692    &       35.398     \\\\\n",
       "\\textbf{C(Generation)[T.3]}              &      21.3662  &        6.998     &     3.053  &         0.002        &        7.629    &       35.103     \\\\\n",
       "\\textbf{C(Generation)[T.4]}              &      31.9575  &        8.235     &     3.881  &         0.000        &       15.793    &       48.122     \\\\\n",
       "\\textbf{C(Generation)[T.5]}              &       9.4926  &        7.883     &     1.204  &         0.229        &       -5.982    &       24.968     \\\\\n",
       "\\textbf{C(Generation)[T.6]}              &      22.2693  &        8.709     &     2.557  &         0.011        &        5.173    &       39.366     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                    &       0.5634  &        0.071     &     7.906  &         0.000        &        0.423    &        0.703     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.2]} &      -0.2350  &        0.101     &    -2.316  &         0.021        &       -0.434    &       -0.036     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.3]} &      -0.3067  &        0.093     &    -3.300  &         0.001        &       -0.489    &       -0.124     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.4]} &      -0.3790  &        0.105     &    -3.600  &         0.000        &       -0.586    &       -0.172     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.5]} &      -0.0484  &        0.108     &    -0.447  &         0.655        &       -0.261    &        0.164     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.6]} &      -0.3083  &        0.112     &    -2.756  &         0.006        &       -0.528    &       -0.089     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 337.229 & \\textbf{  Durbin-Watson:     } &    1.505  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2871.522  \\\\\n",
       "\\textbf{Skew:}          &   1.684 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  11.649 & \\textbf{  Cond. No.          } & 1.40e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.4e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.176\n",
       "Model:                            OLS   Adj. R-squared:                  0.164\n",
       "Method:                 Least Squares   F-statistic:                     15.27\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           3.50e-27\n",
       "Time:                        21:59:51   Log-Likelihood:                -3649.4\n",
       "No. Observations:                 800   AIC:                             7323.\n",
       "Df Residuals:                     788   BIC:                             7379.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================================\n",
       "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "Intercept                          26.8971      5.246      5.127      0.000      16.599      37.195\n",
       "C(Generation)[T.2]                 20.0449      7.821      2.563      0.011       4.692      35.398\n",
       "C(Generation)[T.3]                 21.3662      6.998      3.053      0.002       7.629      35.103\n",
       "C(Generation)[T.4]                 31.9575      8.235      3.881      0.000      15.793      48.122\n",
       "C(Generation)[T.5]                  9.4926      7.883      1.204      0.229      -5.982      24.968\n",
       "C(Generation)[T.6]                 22.2693      8.709      2.557      0.011       5.173      39.366\n",
       "Q(\"Sp. Def\")                        0.5634      0.071      7.906      0.000       0.423       0.703\n",
       "Q(\"Sp. Def\"):C(Generation)[T.2]    -0.2350      0.101     -2.316      0.021      -0.434      -0.036\n",
       "Q(\"Sp. Def\"):C(Generation)[T.3]    -0.3067      0.093     -3.300      0.001      -0.489      -0.124\n",
       "Q(\"Sp. Def\"):C(Generation)[T.4]    -0.3790      0.105     -3.600      0.000      -0.586      -0.172\n",
       "Q(\"Sp. Def\"):C(Generation)[T.5]    -0.0484      0.108     -0.447      0.655      -0.261       0.164\n",
       "Q(\"Sp. Def\"):C(Generation)[T.6]    -0.3083      0.112     -2.756      0.006      -0.528      -0.089\n",
       "==============================================================================\n",
       "Omnibus:                      337.229   Durbin-Watson:                   1.505\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2871.522\n",
       "Skew:                           1.684   Prob(JB):                         0.00\n",
       "Kurtosis:                      11.649   Cond. No.                     1.40e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model1_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation) + Q(\"Sp. Def\"):C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") * C(Generation)', data=pokeaman)\n",
    "\n",
    "model2_fit = model2_spec.fit()\n",
    "model2_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2de1229",
   "metadata": {},
   "source": [
    "### Firstly, the two are not contradictory because they measure different aspects of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da3e10e",
   "metadata": {},
   "source": [
    "### R-squared represents the proportion of variability in the outcome variable (HP) that the model can explain. Here, with an R-squared of only 17.6%, the model explains only a small portion of the variability in HP, which suggests that there may be many other unaccounted-for factors influencing HP. This helps explain why, even with significant coefficients, a large amount of variability remains unexplained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e476bf",
   "metadata": {},
   "source": [
    "### The p-value tests whether each regression coefficient significantly affects the outcome while “holding other variables constant.” Even though the model explains a small proportion of total variability (low R-squared), some coefficients still show statistical significance. This is because the p-value assesses the marginal impact of a particular variable on the outcome, given other variables, rather than the model’s overall explanatory power. Thus, even if the model’s overall explanatory strength is limited, certain variables can still have a strong marginal effect on the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498a8b92",
   "metadata": {},
   "source": [
    "### The p-value assesses the significance of individual variables in the model, while R-squared evaluates the model’s overall fit. Therefore, they serve different purposes and are not contradictory. R-squared reflects the model's explanatory power as a whole, whereas p-values and regression coefficients indicate the significance of specific predictors. This means that, although the model’s overall explanatory power may be low, certain variables can still have a significant impact on the outcome when holding other variables constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6d8b9a",
   "metadata": {},
   "source": [
    "### The model treats \"Generation\" as a categorical variable, represented with binary indicators to capture contrasts with the baseline “Generation 1.” This allows us to measure the effect of each Generation level on HP individually rather than assuming a continuous relationship. The interaction between \"Sp. Def\" and \"Generation\" levels further refines this by capturing how the relationship between HP and \"Sp. Def\" changes across generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0ec7790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. P-values:\n",
      "- Used to assess statistical significance of individual predictors.\n",
      "- A low p-value indicates strong evidence that a predictor has a non-zero effect on the outcome.\n",
      "- This suggests that including this predictor in the model is meaningful.\n",
      "\n",
      "2. R-squared:\n",
      "- Measures the proportion of outcome variability explained by the model.\n",
      "- High R-squared: The model fits well and explains much of the variability.\n",
      "- Low R-squared: The model captures only a small portion of the outcome’s variability.\n",
      "\n",
      "3. Interpretation of Both Together:\n",
      "- P-values and R-squared address different aspects of the model:\n",
      "    - P-values indicate if individual predictors are statistically meaningful.\n",
      "    - R-squared shows how well the model explains overall variability.\n",
      "- They are not contradictory, even if low p-values coexist with a low R-squared.\n",
      "\n",
      "4. Conclusion:\n",
      "- P-value size and R-squared size serve different purposes in model interpretation.\n",
      "- P-value checks if the model is meaningful (significant predictors), while R-squared evaluates the model’s fit (explained variability).\n",
      "\n",
      "Example:\n",
      "This summary shows that low p-values with a low R-squared are not contradictory,\n",
      "as p-values and R-squared assess distinct model aspects.\n"
     ]
    }
   ],
   "source": [
    "# Chat Summary\n",
    "\n",
    "# 1. P-values: Used to assess statistical significance of individual predictors\n",
    "print(\"1. P-values:\")\n",
    "print(\"- Used to assess statistical significance of individual predictors.\")\n",
    "print(\"- A low p-value indicates strong evidence that a predictor has a non-zero effect on the outcome.\")\n",
    "print(\"- This suggests that including this predictor in the model is meaningful.\\n\")\n",
    "\n",
    "# 2. R-squared: Measures the proportion of outcome variability explained by the model\n",
    "print(\"2. R-squared:\")\n",
    "print(\"- Measures the proportion of outcome variability explained by the model.\")\n",
    "print(\"- High R-squared: The model fits well and explains much of the variability.\")\n",
    "print(\"- Low R-squared: The model captures only a small portion of the outcome’s variability.\\n\")\n",
    "\n",
    "# 3. Interpretation of Both Together:\n",
    "print(\"3. Interpretation of Both Together:\")\n",
    "print(\"- P-values and R-squared address different aspects of the model:\")\n",
    "print(\"    - P-values indicate if individual predictors are statistically meaningful.\")\n",
    "print(\"    - R-squared shows how well the model explains overall variability.\")\n",
    "print(\"- They are not contradictory, even if low p-values coexist with a low R-squared.\\n\")\n",
    "\n",
    "# 4. Conclusion:\n",
    "print(\"4. Conclusion:\")\n",
    "print(\"- P-value size and R-squared size serve different purposes in model interpretation.\")\n",
    "print(\"- P-value checks if the model is meaningful (significant predictors), while R-squared evaluates the model’s fit (explained variability).\")\n",
    "\n",
    "# Example conclusion\n",
    "print(\"\\nExample:\")\n",
    "print(\"This summary shows that low p-values with a low R-squared are not contradictory,\")\n",
    "print(\"as p-values and R-squared assess distinct model aspects.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03f07d6",
   "metadata": {},
   "source": [
    "link with ChatGPT: https://chatgpt.com/share/67367284-08bc-800d-a09d-6a454f2689da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5ea0e2",
   "metadata": {},
   "source": [
    "# Post-lecture HW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd997879",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32ebcdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>338</td>\n",
       "      <td>Solrock</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>70</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Charizard</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Flying</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>109</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>224</td>\n",
       "      <td>Octillery</td>\n",
       "      <td>Water</td>\n",
       "      <td>None</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>600</td>\n",
       "      <td>Klang</td>\n",
       "      <td>Steel</td>\n",
       "      <td>None</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>265</td>\n",
       "      <td>Wurmple</td>\n",
       "      <td>Bug</td>\n",
       "      <td>None</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>471</td>\n",
       "      <td>Glaceon</td>\n",
       "      <td>Ice</td>\n",
       "      <td>None</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>130</td>\n",
       "      <td>95</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>225</td>\n",
       "      <td>Delibird</td>\n",
       "      <td>Ice</td>\n",
       "      <td>Flying</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>109</td>\n",
       "      <td>Koffing</td>\n",
       "      <td>Poison</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>373</td>\n",
       "      <td>SalamenceMega Salamence</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>Flying</td>\n",
       "      <td>95</td>\n",
       "      <td>145</td>\n",
       "      <td>130</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                     Name   Type 1   Type 2  HP  Attack  Defense  \\\n",
       "370  338                  Solrock     Rock  Psychic  70      95       85   \n",
       "6      6                Charizard     Fire   Flying  78      84       78   \n",
       "242  224                Octillery    Water     None  75     105       75   \n",
       "661  600                    Klang    Steel     None  60      80       95   \n",
       "288  265                  Wurmple      Bug     None  45      45       35   \n",
       "..   ...                      ...      ...      ...  ..     ...      ...   \n",
       "522  471                  Glaceon      Ice     None  65      60      110   \n",
       "243  225                 Delibird      Ice   Flying  45      55       45   \n",
       "797  720      HoopaHoopa Confined  Psychic    Ghost  80     110       60   \n",
       "117  109                  Koffing   Poison     None  40      65       95   \n",
       "409  373  SalamenceMega Salamence   Dragon   Flying  95     145      130   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "370       55       65     70           3      False  \n",
       "6        109       85    100           1      False  \n",
       "242      105       75     45           2      False  \n",
       "661       70       85     50           5      False  \n",
       "288       20       30     20           3      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "522      130       95     65           4      False  \n",
       "243       65       45     75           2      False  \n",
       "797      150      130     70           6       True  \n",
       "117       60       45     35           1      False  \n",
       "409      120       90    120           3      False  \n",
       "\n",
       "[400 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fifty_fifty_split_size = int(pokeaman.shape[0]*0.5)\n",
    "\n",
    "# Replace \"NaN\" (in the \"Type 2\" column with \"None\")\n",
    "pokeaman.fillna('None', inplace=True)\n",
    "\n",
    "np.random.seed(130)\n",
    "pokeaman_train,pokeaman_test = \\\n",
    "  train_test_split(pokeaman, train_size=fifty_fifty_split_size)\n",
    "pokeaman_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2df9c977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:24:37</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   42.5882</td> <td>    3.580</td> <td>   11.897</td> <td> 0.000</td> <td>   35.551</td> <td>   49.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>    <td>    0.2472</td> <td>    0.041</td> <td>    6.051</td> <td> 0.000</td> <td>    0.167</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>   <td>    0.1001</td> <td>    0.045</td> <td>    2.201</td> <td> 0.028</td> <td>    0.011</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    343.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}             & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}             &     22:24:37     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}     &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      42.5882  &        3.580     &    11.897  &         0.000        &       35.551    &       49.626     \\\\\n",
       "\\textbf{Attack}    &       0.2472  &        0.041     &     6.051  &         0.000        &        0.167    &        0.327     \\\\\n",
       "\\textbf{Defense}   &       0.1001  &        0.045     &     2.201  &         0.028        &        0.011    &        0.190     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     343.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        22:24:37   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     42.5882      3.580     11.897      0.000      35.551      49.626\n",
       "Attack         0.2472      0.041      6.051      0.000       0.167       0.327\n",
       "Defense        0.1001      0.045      2.201      0.028       0.011       0.190\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         343.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spec3 = smf.ols(formula='HP ~ Attack + Defense', \n",
    "                      data=pokeaman_train)\n",
    "model3_fit = model_spec3.fit()\n",
    "model3_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3af6d80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.14771558304519894\n",
      "'Out of sample' R-squared: 0.21208501873920738\n"
     ]
    }
   ],
   "source": [
    "yhat_model3 = model3_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model3_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model3)[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd31d848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>4.23e-21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:24:56</td>     <th>  Log-Likelihood:    </th> <td> -1738.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3603.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   337</td>      <th>  BIC:               </th> <td>   3855.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    62</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                  <td></td>                                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                        <td>  521.5715</td> <td>  130.273</td> <td>    4.004</td> <td> 0.000</td> <td>  265.322</td> <td>  777.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>                                                <td>   -6.1179</td> <td>    2.846</td> <td>   -2.150</td> <td> 0.032</td> <td>  -11.716</td> <td>   -0.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                                           <td>   -8.1938</td> <td>    2.329</td> <td>   -3.518</td> <td> 0.000</td> <td>  -12.775</td> <td>   -3.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]</th>                                         <td>-1224.9610</td> <td>  545.105</td> <td>   -2.247</td> <td> 0.025</td> <td>-2297.199</td> <td> -152.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                                                          <td>   -6.1989</td> <td>    2.174</td> <td>   -2.851</td> <td> 0.005</td> <td>  -10.475</td> <td>   -1.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]</th>                                        <td> -102.4030</td> <td>   96.565</td> <td>   -1.060</td> <td> 0.290</td> <td> -292.350</td> <td>   87.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense</th>                                                   <td>    0.0985</td> <td>    0.033</td> <td>    2.982</td> <td> 0.003</td> <td>    0.034</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]</th>                                 <td>   14.6361</td> <td>    6.267</td> <td>    2.336</td> <td> 0.020</td> <td>    2.310</td> <td>   26.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                                                            <td>   -7.2261</td> <td>    2.178</td> <td>   -3.318</td> <td> 0.001</td> <td>  -11.511</td> <td>   -2.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]</th>                                          <td>  704.8798</td> <td>  337.855</td> <td>    2.086</td> <td> 0.038</td> <td>   40.309</td> <td> 1369.450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed</th>                                                     <td>    0.1264</td> <td>    0.038</td> <td>    3.351</td> <td> 0.001</td> <td>    0.052</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]</th>                                   <td>    5.8648</td> <td>    2.692</td> <td>    2.179</td> <td> 0.030</td> <td>    0.570</td> <td>   11.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed</th>                                                    <td>    0.1026</td> <td>    0.039</td> <td>    2.634</td> <td> 0.009</td> <td>    0.026</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]</th>                                  <td>   -6.9266</td> <td>    3.465</td> <td>   -1.999</td> <td> 0.046</td> <td>  -13.742</td> <td>   -0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed</th>                                             <td>   -0.0016</td> <td>    0.001</td> <td>   -2.837</td> <td> 0.005</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]</th>                           <td>   -0.0743</td> <td>    0.030</td> <td>   -2.477</td> <td> 0.014</td> <td>   -0.133</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                                                     <td>   -5.3982</td> <td>    1.938</td> <td>   -2.785</td> <td> 0.006</td> <td>   -9.211</td> <td>   -1.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\")</th>                                   <td> -282.2496</td> <td>  126.835</td> <td>   -2.225</td> <td> 0.027</td> <td> -531.738</td> <td>  -32.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\")</th>                                              <td>    0.1094</td> <td>    0.034</td> <td>    3.233</td> <td> 0.001</td> <td>    0.043</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\")</th>                            <td>   12.6503</td> <td>    5.851</td> <td>    2.162</td> <td> 0.031</td> <td>    1.141</td> <td>   24.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\")</th>                                             <td>    0.0628</td> <td>    0.028</td> <td>    2.247</td> <td> 0.025</td> <td>    0.008</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                           <td>    3.3949</td> <td>    1.783</td> <td>    1.904</td> <td> 0.058</td> <td>   -0.112</td> <td>    6.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\")</th>                                      <td>   -0.0012</td> <td>    0.000</td> <td>   -2.730</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                    <td>   -0.1456</td> <td>    0.065</td> <td>   -2.253</td> <td> 0.025</td> <td>   -0.273</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\")</th>                                               <td>    0.0624</td> <td>    0.031</td> <td>    2.027</td> <td> 0.043</td> <td>    0.002</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                             <td>   -3.2219</td> <td>    1.983</td> <td>   -1.625</td> <td> 0.105</td> <td>   -7.122</td> <td>    0.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\")</th>                                        <td>   -0.0014</td> <td>    0.001</td> <td>   -2.732</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                      <td>   -0.0695</td> <td>    0.033</td> <td>   -2.100</td> <td> 0.036</td> <td>   -0.135</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\")</th>                                       <td>   -0.0008</td> <td>    0.000</td> <td>   -1.743</td> <td> 0.082</td> <td>   -0.002</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                     <td>    0.0334</td> <td>    0.021</td> <td>    1.569</td> <td> 0.117</td> <td>   -0.008</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\")</th>                                <td> 1.629e-05</td> <td> 6.92e-06</td> <td>    2.355</td> <td> 0.019</td> <td> 2.68e-06</td> <td> 2.99e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>              <td>    0.0008</td> <td>    0.000</td> <td>    2.433</td> <td> 0.015</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                                                     <td>   -8.3636</td> <td>    2.346</td> <td>   -3.565</td> <td> 0.000</td> <td>  -12.978</td> <td>   -3.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Atk\")</th>                                   <td>  850.5436</td> <td>  385.064</td> <td>    2.209</td> <td> 0.028</td> <td>   93.112</td> <td> 1607.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Atk\")</th>                                              <td>    0.1388</td> <td>    0.040</td> <td>    3.500</td> <td> 0.001</td> <td>    0.061</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Atk\")</th>                            <td>    2.1809</td> <td>    1.136</td> <td>    1.920</td> <td> 0.056</td> <td>   -0.054</td> <td>    4.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Atk\")</th>                                             <td>    0.0831</td> <td>    0.038</td> <td>    2.162</td> <td> 0.031</td> <td>    0.007</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                           <td>   -7.3121</td> <td>    3.376</td> <td>   -2.166</td> <td> 0.031</td> <td>  -13.953</td> <td>   -0.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Atk\")</th>                                      <td>   -0.0014</td> <td>    0.001</td> <td>   -2.480</td> <td> 0.014</td> <td>   -0.003</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                    <td>   -0.0434</td> <td>    0.022</td> <td>   -2.010</td> <td> 0.045</td> <td>   -0.086</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Atk\")</th>                                               <td>    0.1011</td> <td>    0.035</td> <td>    2.872</td> <td> 0.004</td> <td>    0.032</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                             <td>  -12.6343</td> <td>    5.613</td> <td>   -2.251</td> <td> 0.025</td> <td>  -23.674</td> <td>   -1.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Atk\")</th>                                        <td>   -0.0018</td> <td>    0.001</td> <td>   -3.102</td> <td> 0.002</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                      <td>    0.0151</td> <td>    0.009</td> <td>    1.609</td> <td> 0.109</td> <td>   -0.003</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Atk\")</th>                                       <td>   -0.0012</td> <td>    0.001</td> <td>   -1.860</td> <td> 0.064</td> <td>   -0.002</td> <td> 6.62e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                     <td>    0.1210</td> <td>    0.054</td> <td>    2.260</td> <td> 0.024</td> <td>    0.016</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Atk\")</th>                                <td> 2.125e-05</td> <td>  9.1e-06</td> <td>    2.334</td> <td> 0.020</td> <td> 3.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>              <td> 6.438e-06</td> <td> 7.69e-05</td> <td>    0.084</td> <td> 0.933</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                        <td>    0.1265</td> <td>    0.033</td> <td>    3.821</td> <td> 0.000</td> <td>    0.061</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                      <td>   -5.0544</td> <td>    2.506</td> <td>   -2.017</td> <td> 0.044</td> <td>   -9.983</td> <td>   -0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                 <td>   -0.0021</td> <td>    0.001</td> <td>   -3.606</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>               <td>   -0.0346</td> <td>    0.017</td> <td>   -1.992</td> <td> 0.047</td> <td>   -0.069</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                <td>   -0.0012</td> <td>    0.000</td> <td>   -2.406</td> <td> 0.017</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>              <td>    0.0446</td> <td>    0.025</td> <td>    1.794</td> <td> 0.074</td> <td>   -0.004</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                         <td> 1.973e-05</td> <td> 7.28e-06</td> <td>    2.710</td> <td> 0.007</td> <td> 5.41e-06</td> <td>  3.4e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>       <td>    0.0005</td> <td>    0.000</td> <td>    1.957</td> <td> 0.051</td> <td>-2.56e-06</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                  <td>   -0.0013</td> <td>    0.000</td> <td>   -2.740</td> <td> 0.006</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                <td>    0.0841</td> <td>    0.040</td> <td>    2.125</td> <td> 0.034</td> <td>    0.006</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                           <td> 2.379e-05</td> <td> 7.85e-06</td> <td>    3.030</td> <td> 0.003</td> <td> 8.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>         <td> 2.864e-05</td> <td> 7.73e-05</td> <td>    0.370</td> <td> 0.711</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                          <td> 1.284e-05</td> <td> 7.46e-06</td> <td>    1.721</td> <td> 0.086</td> <td>-1.83e-06</td> <td> 2.75e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>        <td>   -0.0008</td> <td>    0.000</td> <td>   -2.085</td> <td> 0.038</td> <td>   -0.002</td> <td>-4.68e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                   <td> -2.53e-07</td> <td>  1.1e-07</td> <td>   -2.292</td> <td> 0.023</td> <td> -4.7e-07</td> <td>-3.59e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th> <td>-1.425e-06</td> <td> 1.14e-06</td> <td>   -1.249</td> <td> 0.212</td> <td>-3.67e-06</td> <td> 8.19e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.20e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.2e+16. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                                   &        HP        & \\textbf{  R-squared:         } &     0.467   \\\\\n",
       "\\textbf{Model:}                                                           &       OLS        & \\textbf{  Adj. R-squared:    } &     0.369   \\\\\n",
       "\\textbf{Method:}                                                          &  Least Squares   & \\textbf{  F-statistic:       } &     4.764   \\\\\n",
       "\\textbf{Date:}                                                            & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  4.23e-21   \\\\\n",
       "\\textbf{Time:}                                                            &     22:24:56     & \\textbf{  Log-Likelihood:    } &   -1738.6   \\\\\n",
       "\\textbf{No. Observations:}                                                &         400      & \\textbf{  AIC:               } &     3603.   \\\\\n",
       "\\textbf{Df Residuals:}                                                    &         337      & \\textbf{  BIC:               } &     3855.   \\\\\n",
       "\\textbf{Df Model:}                                                        &          62      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                                                 &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                                        &     521.5715  &      130.273     &     4.004  &         0.000        &      265.322    &      777.821     \\\\\n",
       "\\textbf{Legendary[T.True]}                                                &      -6.1179  &        2.846     &    -2.150  &         0.032        &      -11.716    &       -0.520     \\\\\n",
       "\\textbf{Attack}                                                           &      -8.1938  &        2.329     &    -3.518  &         0.000        &      -12.775    &       -3.612     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]}                                         &   -1224.9610  &      545.105     &    -2.247  &         0.025        &    -2297.199    &     -152.723     \\\\\n",
       "\\textbf{Defense}                                                          &      -6.1989  &        2.174     &    -2.851  &         0.005        &      -10.475    &       -1.923     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]}                                        &    -102.4030  &       96.565     &    -1.060  &         0.290        &     -292.350    &       87.544     \\\\\n",
       "\\textbf{Attack:Defense}                                                   &       0.0985  &        0.033     &     2.982  &         0.003        &        0.034    &        0.164     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]}                                 &      14.6361  &        6.267     &     2.336  &         0.020        &        2.310    &       26.963     \\\\\n",
       "\\textbf{Speed}                                                            &      -7.2261  &        2.178     &    -3.318  &         0.001        &      -11.511    &       -2.942     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]}                                          &     704.8798  &      337.855     &     2.086  &         0.038        &       40.309    &     1369.450     \\\\\n",
       "\\textbf{Attack:Speed}                                                     &       0.1264  &        0.038     &     3.351  &         0.001        &        0.052    &        0.201     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]}                                   &       5.8648  &        2.692     &     2.179  &         0.030        &        0.570    &       11.160     \\\\\n",
       "\\textbf{Defense:Speed}                                                    &       0.1026  &        0.039     &     2.634  &         0.009        &        0.026    &        0.179     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]}                                  &      -6.9266  &        3.465     &    -1.999  &         0.046        &      -13.742    &       -0.111     \\\\\n",
       "\\textbf{Attack:Defense:Speed}                                             &      -0.0016  &        0.001     &    -2.837  &         0.005        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]}                           &      -0.0743  &        0.030     &    -2.477  &         0.014        &       -0.133    &       -0.015     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                                                     &      -5.3982  &        1.938     &    -2.785  &         0.006        &       -9.211    &       -1.586     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\")}                                   &    -282.2496  &      126.835     &    -2.225  &         0.027        &     -531.738    &      -32.761     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\")}                                              &       0.1094  &        0.034     &     3.233  &         0.001        &        0.043    &        0.176     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\")}                            &      12.6503  &        5.851     &     2.162  &         0.031        &        1.141    &       24.160     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\")}                                             &       0.0628  &        0.028     &     2.247  &         0.025        &        0.008    &        0.118     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\")}                           &       3.3949  &        1.783     &     1.904  &         0.058        &       -0.112    &        6.902     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\")}                                      &      -0.0012  &        0.000     &    -2.730  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")}                    &      -0.1456  &        0.065     &    -2.253  &         0.025        &       -0.273    &       -0.018     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\")}                                               &       0.0624  &        0.031     &     2.027  &         0.043        &        0.002    &        0.123     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\")}                             &      -3.2219  &        1.983     &    -1.625  &         0.105        &       -7.122    &        0.678     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\")}                                        &      -0.0014  &        0.001     &    -2.732  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                      &      -0.0695  &        0.033     &    -2.100  &         0.036        &       -0.135    &       -0.004     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\")}                                       &      -0.0008  &        0.000     &    -1.743  &         0.082        &       -0.002    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                     &       0.0334  &        0.021     &     1.569  &         0.117        &       -0.008    &        0.075     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\")}                                &    1.629e-05  &     6.92e-06     &     2.355  &         0.019        &     2.68e-06    &     2.99e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}              &       0.0008  &        0.000     &     2.433  &         0.015        &        0.000    &        0.001     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                                                     &      -8.3636  &        2.346     &    -3.565  &         0.000        &      -12.978    &       -3.749     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Atk\")}                                   &     850.5436  &      385.064     &     2.209  &         0.028        &       93.112    &     1607.975     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Atk\")}                                              &       0.1388  &        0.040     &     3.500  &         0.001        &        0.061    &        0.217     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Atk\")}                            &       2.1809  &        1.136     &     1.920  &         0.056        &       -0.054    &        4.416     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Atk\")}                                             &       0.0831  &        0.038     &     2.162  &         0.031        &        0.007    &        0.159     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                           &      -7.3121  &        3.376     &    -2.166  &         0.031        &      -13.953    &       -0.671     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Atk\")}                                      &      -0.0014  &        0.001     &    -2.480  &         0.014        &       -0.003    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                    &      -0.0434  &        0.022     &    -2.010  &         0.045        &       -0.086    &       -0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Atk\")}                                               &       0.1011  &        0.035     &     2.872  &         0.004        &        0.032    &        0.170     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                             &     -12.6343  &        5.613     &    -2.251  &         0.025        &      -23.674    &       -1.594     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Atk\")}                                        &      -0.0018  &        0.001     &    -3.102  &         0.002        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                      &       0.0151  &        0.009     &     1.609  &         0.109        &       -0.003    &        0.034     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Atk\")}                                       &      -0.0012  &        0.001     &    -1.860  &         0.064        &       -0.002    &     6.62e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                     &       0.1210  &        0.054     &     2.260  &         0.024        &        0.016    &        0.226     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Atk\")}                                &    2.125e-05  &      9.1e-06     &     2.334  &         0.020        &     3.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}              &    6.438e-06  &     7.69e-05     &     0.084  &         0.933        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                        &       0.1265  &        0.033     &     3.821  &         0.000        &        0.061    &        0.192     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                      &      -5.0544  &        2.506     &    -2.017  &         0.044        &       -9.983    &       -0.126     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                 &      -0.0021  &        0.001     &    -3.606  &         0.000        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}               &      -0.0346  &        0.017     &    -1.992  &         0.047        &       -0.069    &       -0.000     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                &      -0.0012  &        0.000     &    -2.406  &         0.017        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}              &       0.0446  &        0.025     &     1.794  &         0.074        &       -0.004    &        0.093     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                         &    1.973e-05  &     7.28e-06     &     2.710  &         0.007        &     5.41e-06    &      3.4e-05     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}       &       0.0005  &        0.000     &     1.957  &         0.051        &    -2.56e-06    &        0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                  &      -0.0013  &        0.000     &    -2.740  &         0.006        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                &       0.0841  &        0.040     &     2.125  &         0.034        &        0.006    &        0.162     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                           &    2.379e-05  &     7.85e-06     &     3.030  &         0.003        &     8.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}         &    2.864e-05  &     7.73e-05     &     0.370  &         0.711        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                          &    1.284e-05  &     7.46e-06     &     1.721  &         0.086        &    -1.83e-06    &     2.75e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}        &      -0.0008  &        0.000     &    -2.085  &         0.038        &       -0.002    &    -4.68e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                   &    -2.53e-07  &      1.1e-07     &    -2.292  &         0.023        &     -4.7e-07    &    -3.59e-08     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")} &   -1.425e-06  &     1.14e-06     &    -1.249  &         0.212        &    -3.67e-06    &     8.19e-07     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.664  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.20e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.2e+16. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.467\n",
       "Model:                            OLS   Adj. R-squared:                  0.369\n",
       "Method:                 Least Squares   F-statistic:                     4.764\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           4.23e-21\n",
       "Time:                        22:24:56   Log-Likelihood:                -1738.6\n",
       "No. Observations:                 400   AIC:                             3603.\n",
       "Df Residuals:                     337   BIC:                             3855.\n",
       "Df Model:                          62                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================================================================\n",
       "                                                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                          521.5715    130.273      4.004      0.000     265.322     777.821\n",
       "Legendary[T.True]                                                   -6.1179      2.846     -2.150      0.032     -11.716      -0.520\n",
       "Attack                                                              -8.1938      2.329     -3.518      0.000     -12.775      -3.612\n",
       "Attack:Legendary[T.True]                                         -1224.9610    545.105     -2.247      0.025   -2297.199    -152.723\n",
       "Defense                                                             -6.1989      2.174     -2.851      0.005     -10.475      -1.923\n",
       "Defense:Legendary[T.True]                                         -102.4030     96.565     -1.060      0.290    -292.350      87.544\n",
       "Attack:Defense                                                       0.0985      0.033      2.982      0.003       0.034       0.164\n",
       "Attack:Defense:Legendary[T.True]                                    14.6361      6.267      2.336      0.020       2.310      26.963\n",
       "Speed                                                               -7.2261      2.178     -3.318      0.001     -11.511      -2.942\n",
       "Speed:Legendary[T.True]                                            704.8798    337.855      2.086      0.038      40.309    1369.450\n",
       "Attack:Speed                                                         0.1264      0.038      3.351      0.001       0.052       0.201\n",
       "Attack:Speed:Legendary[T.True]                                       5.8648      2.692      2.179      0.030       0.570      11.160\n",
       "Defense:Speed                                                        0.1026      0.039      2.634      0.009       0.026       0.179\n",
       "Defense:Speed:Legendary[T.True]                                     -6.9266      3.465     -1.999      0.046     -13.742      -0.111\n",
       "Attack:Defense:Speed                                                -0.0016      0.001     -2.837      0.005      -0.003      -0.001\n",
       "Attack:Defense:Speed:Legendary[T.True]                              -0.0743      0.030     -2.477      0.014      -0.133      -0.015\n",
       "Q(\"Sp. Def\")                                                        -5.3982      1.938     -2.785      0.006      -9.211      -1.586\n",
       "Legendary[T.True]:Q(\"Sp. Def\")                                    -282.2496    126.835     -2.225      0.027    -531.738     -32.761\n",
       "Attack:Q(\"Sp. Def\")                                                  0.1094      0.034      3.233      0.001       0.043       0.176\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\")                               12.6503      5.851      2.162      0.031       1.141      24.160\n",
       "Defense:Q(\"Sp. Def\")                                                 0.0628      0.028      2.247      0.025       0.008       0.118\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\")                               3.3949      1.783      1.904      0.058      -0.112       6.902\n",
       "Attack:Defense:Q(\"Sp. Def\")                                         -0.0012      0.000     -2.730      0.007      -0.002      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")                       -0.1456      0.065     -2.253      0.025      -0.273      -0.018\n",
       "Speed:Q(\"Sp. Def\")                                                   0.0624      0.031      2.027      0.043       0.002       0.123\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\")                                -3.2219      1.983     -1.625      0.105      -7.122       0.678\n",
       "Attack:Speed:Q(\"Sp. Def\")                                           -0.0014      0.001     -2.732      0.007      -0.002      -0.000\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         -0.0695      0.033     -2.100      0.036      -0.135      -0.004\n",
       "Defense:Speed:Q(\"Sp. Def\")                                          -0.0008      0.000     -1.743      0.082      -0.002       0.000\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         0.0334      0.021      1.569      0.117      -0.008       0.075\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\")                                 1.629e-05   6.92e-06      2.355      0.019    2.68e-06    2.99e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                  0.0008      0.000      2.433      0.015       0.000       0.001\n",
       "Q(\"Sp. Atk\")                                                        -8.3636      2.346     -3.565      0.000     -12.978      -3.749\n",
       "Legendary[T.True]:Q(\"Sp. Atk\")                                     850.5436    385.064      2.209      0.028      93.112    1607.975\n",
       "Attack:Q(\"Sp. Atk\")                                                  0.1388      0.040      3.500      0.001       0.061       0.217\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Atk\")                                2.1809      1.136      1.920      0.056      -0.054       4.416\n",
       "Defense:Q(\"Sp. Atk\")                                                 0.0831      0.038      2.162      0.031       0.007       0.159\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Atk\")                              -7.3121      3.376     -2.166      0.031     -13.953      -0.671\n",
       "Attack:Defense:Q(\"Sp. Atk\")                                         -0.0014      0.001     -2.480      0.014      -0.003      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")                       -0.0434      0.022     -2.010      0.045      -0.086      -0.001\n",
       "Speed:Q(\"Sp. Atk\")                                                   0.1011      0.035      2.872      0.004       0.032       0.170\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Atk\")                               -12.6343      5.613     -2.251      0.025     -23.674      -1.594\n",
       "Attack:Speed:Q(\"Sp. Atk\")                                           -0.0018      0.001     -3.102      0.002      -0.003      -0.001\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                          0.0151      0.009      1.609      0.109      -0.003       0.034\n",
       "Defense:Speed:Q(\"Sp. Atk\")                                          -0.0012      0.001     -1.860      0.064      -0.002    6.62e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                         0.1210      0.054      2.260      0.024       0.016       0.226\n",
       "Attack:Defense:Speed:Q(\"Sp. Atk\")                                 2.125e-05    9.1e-06      2.334      0.020    3.34e-06    3.92e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")               6.438e-06   7.69e-05      0.084      0.933      -0.000       0.000\n",
       "Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                            0.1265      0.033      3.821      0.000       0.061       0.192\n",
       "Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                         -5.0544      2.506     -2.017      0.044      -9.983      -0.126\n",
       "Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                    -0.0021      0.001     -3.606      0.000      -0.003      -0.001\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  -0.0346      0.017     -1.992      0.047      -0.069      -0.000\n",
       "Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                   -0.0012      0.000     -2.406      0.017      -0.002      -0.000\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  0.0446      0.025      1.794      0.074      -0.004       0.093\n",
       "Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                          1.973e-05   7.28e-06      2.710      0.007    5.41e-06     3.4e-05\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           0.0005      0.000      1.957      0.051   -2.56e-06       0.001\n",
       "Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                     -0.0013      0.000     -2.740      0.006      -0.002      -0.000\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    0.0841      0.040      2.125      0.034       0.006       0.162\n",
       "Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                            2.379e-05   7.85e-06      3.030      0.003    8.34e-06    3.92e-05\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")          2.864e-05   7.73e-05      0.370      0.711      -0.000       0.000\n",
       "Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                           1.284e-05   7.46e-06      1.721      0.086   -1.83e-06    2.75e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           -0.0008      0.000     -2.085      0.038      -0.002   -4.68e-05\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    -2.53e-07    1.1e-07     -2.292      0.023    -4.7e-07   -3.59e-08\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\") -1.425e-06   1.14e-06     -1.249      0.212   -3.67e-06    8.19e-07\n",
       "==============================================================================\n",
       "Omnibus:                      214.307   Durbin-Watson:                   1.992\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2354.664\n",
       "Skew:                           2.026   Prob(JB):                         0.00\n",
       "Kurtosis:                      14.174   Cond. No.                     1.20e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.2e+16. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_linear_form = 'HP ~ Attack * Defense * Speed * Legendary'\n",
    "model4_linear_form += ' * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "# DO NOT try adding '* C(Generation) * C(Q(\"Type 1\")) * C(Q(\"Type 2\"))'\n",
    "# That's 6*18*19 = 6*18*19 possible interaction combinations...\n",
    "# ...a huge number that will blow up your computer\n",
    "\n",
    "model4_spec = smf.ols(formula=model4_linear_form, data=pokeaman_train)\n",
    "model4_fit = model4_spec.fit()\n",
    "model4_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23622cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.46709442115833855\n",
      "'Out of sample' R-squared: 0.002485342598992873\n"
     ]
    }
   ],
   "source": [
    "yhat_model4 = model4_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model4_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model4)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd2cf60",
   "metadata": {},
   "source": [
    "### Model 3 is a simple linear regression model that uses only the variables Attack and Defense to predict HP. This model has low complexity, favoring a basic prediction approach by avoiding an excess of features and interaction terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ff200",
   "metadata": {},
   "source": [
    "### Model 4, on the other hand, is a complex regression model that uses multiple variables and interaction terms to predict HP. It aims to fit the patterns in the data more precisely but also carries a higher risk of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbc70e9",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f2feb2",
   "metadata": {},
   "source": [
    "### The in-sample R-squared is 0.1477, and the out-of-sample R-squared is 0.2121. Both values are relatively low, indicating that Model 3 has limited ability to explain the target variable, HP. Since the in-sample and out-of-sample R-squared values are close, this suggests the model performs consistently on both the training and test sets, without significant signs of overfitting. However, the low R-squared values suggest the model may suffer from underfitting, as it fails to effectively capture complex patterns and structures in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc99de5d",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed2a6ab",
   "metadata": {},
   "source": [
    "### The in-sample R-squared is 0.4671, indicating that Model 4 explains approximately 46.7% of the variation in HP within the training set, showing a relatively good fit. However, the out-of-sample R-squared is only 0.0025, which is nearly zero. This demonstrates that Model 4 performs very poorly on the test set, almost entirely failing to explain the variation in HP.The significant gap between the in-sample and out-of-sample R-squared values indicates that Model 4 has overfit the specific patterns and noise in the training data, and it lacks the ability to generalize effectively to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f63d3b",
   "metadata": {},
   "source": [
    "### By comparing the in-sample and out-of-sample R-squared values for Models 3 and 4, we reach the following conclusions: Model 3 shows relatively stable performance, but its low R-squared values suggest potential underfitting. Model 4 performs well on the training set but performs very poorly on the test set, indicating overfitting. This comparison demonstrates that increasing model complexity does not necessarily improve performance on new data. Appropriate feature selection and managing model complexity are essential for enhancing a model's ability to generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e33519bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User Question': 'I will next provide you the R-squared in both model 3 and 4, help me analyze the data and respond to the questions.', 'Assistant Response': 'Great! Once you provide the R-squared values for models 3 and 4, I’ll help you analyze the data and respond to the questions about model performance and generalizability.'}\n",
      "{'User Provided Data': {'Model 3': {'In-sample R-squared': 0.14771558304519894, 'Out-of-sample R-squared': 0.21208501873920738}, 'Model 4': {'In-sample R-squared': 0.46709442115833855, 'Out-of-sample R-squared': 0.002485342598992873}}, 'User Question': \"'In sample' R-squared: 0.14771558304519894 'Out of sample' R-squared: 0.21208501873920738 (model 3) 'In sample' R-squared: 0.46709442115833855 'Out of sample' R-squared: 0.002485342598992873 (model 4)\", 'Assistant Analysis': {'Model 3 Analysis': 'The out-of-sample R-squared is slightly higher than the in-sample R-squared, suggesting some generalizability, though both values are low, indicating underfitting.', 'Model 4 Analysis': 'There is a significant drop from in-sample to out-of-sample R-squared, indicating overfitting as it performs well on training data but poorly on testing data.', 'Conclusion': {'Model 3': 'Underfitting.', 'Model 4': 'Overfitting.'}}}\n",
      "{'User Question': 'So model 3 is underfitting and model 4 is overfitting, right?', 'Assistant Confirmation': \"Yes, that's correct! Model 3 is underfitting with low R-squared values in both contexts, while model 4 is overfitting, with a high in-sample R-squared but poor out-of-sample performance.\"}\n",
      "{'User Request': 'I need the chat summary.', 'Assistant Summary': 'The user provided R-squared values for models 3 and 4. Model 3 showed low R-squared values in both in-sample and out-of-sample contexts, suggesting underfitting. Model 4 had a high in-sample R-squared but a near-zero out-of-sample R-squared, indicating overfitting.'}\n"
     ]
    }
   ],
   "source": [
    "# Chat Summary\n",
    "\n",
    "chat_log = [\n",
    "    {\n",
    "        \"User Question\": \"I will next provide you the R-squared in both model 3 and 4, help me analyze the data and respond to the questions.\",\n",
    "        \"Assistant Response\": \"Great! Once you provide the R-squared values for models 3 and 4, I’ll help you analyze the data and respond to the questions about model performance and generalizability.\"\n",
    "    },\n",
    "    {\n",
    "        \"User Provided Data\": {\n",
    "            \"Model 3\": {\n",
    "                \"In-sample R-squared\": 0.14771558304519894,\n",
    "                \"Out-of-sample R-squared\": 0.21208501873920738\n",
    "            },\n",
    "            \"Model 4\": {\n",
    "                \"In-sample R-squared\": 0.46709442115833855,\n",
    "                \"Out-of-sample R-squared\": 0.002485342598992873\n",
    "            }\n",
    "        },\n",
    "        \"User Question\": \"'In sample' R-squared: 0.14771558304519894 'Out of sample' R-squared: 0.21208501873920738 (model 3) 'In sample' R-squared: 0.46709442115833855 'Out of sample' R-squared: 0.002485342598992873 (model 4)\",\n",
    "        \"Assistant Analysis\": {\n",
    "            \"Model 3 Analysis\": \"The out-of-sample R-squared is slightly higher than the in-sample R-squared, suggesting some generalizability, though both values are low, indicating underfitting.\",\n",
    "            \"Model 4 Analysis\": \"There is a significant drop from in-sample to out-of-sample R-squared, indicating overfitting as it performs well on training data but poorly on testing data.\",\n",
    "            \"Conclusion\": {\n",
    "                \"Model 3\": \"Underfitting.\",\n",
    "                \"Model 4\": \"Overfitting.\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"User Question\": \"So model 3 is underfitting and model 4 is overfitting, right?\",\n",
    "        \"Assistant Confirmation\": \"Yes, that's correct! Model 3 is underfitting with low R-squared values in both contexts, while model 4 is overfitting, with a high in-sample R-squared but poor out-of-sample performance.\"\n",
    "    },\n",
    "    {\n",
    "        \"User Request\": \"I need the chat summary.\",\n",
    "        \"Assistant Summary\": \"The user provided R-squared values for models 3 and 4. Model 3 showed low R-squared values in both in-sample and out-of-sample contexts, suggesting underfitting. Model 4 had a high in-sample R-squared but a near-zero out-of-sample R-squared, indicating overfitting.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Displaying chat log summary\n",
    "for entry in chat_log:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7efe7a",
   "metadata": {},
   "source": [
    "link with ChatGPT: https://chatgpt.com/share/67367eca-c6c0-800d-b4cf-d6cab9b08e53"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f25006b",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f2d9c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:26:48</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   42.5882</td> <td>    3.580</td> <td>   11.897</td> <td> 0.000</td> <td>   35.551</td> <td>   49.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>    <td>    0.2472</td> <td>    0.041</td> <td>    6.051</td> <td> 0.000</td> <td>    0.167</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>   <td>    0.1001</td> <td>    0.045</td> <td>    2.201</td> <td> 0.028</td> <td>    0.011</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    343.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}             & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}             &     23:26:48     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}     &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      42.5882  &        3.580     &    11.897  &         0.000        &       35.551    &       49.626     \\\\\n",
       "\\textbf{Attack}    &       0.2472  &        0.041     &     6.051  &         0.000        &        0.167    &        0.327     \\\\\n",
       "\\textbf{Defense}   &       0.1001  &        0.045     &     2.201  &         0.028        &        0.011    &        0.190     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     343.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        23:26:48   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     42.5882      3.580     11.897      0.000      35.551      49.626\n",
       "Attack         0.2472      0.041      6.051      0.000       0.167       0.327\n",
       "Defense        0.1001      0.045      2.201      0.028       0.011       0.190\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         343.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Cond. No.\" WAS 343.0 WITHOUT to centering and scaling\n",
    "model3_fit.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eb65ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:26:55</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>              <td>   69.3025</td> <td>    1.186</td> <td>   58.439</td> <td> 0.000</td> <td>   66.971</td> <td>   71.634</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(center(Attack))</th>  <td>    8.1099</td> <td>    1.340</td> <td>    6.051</td> <td> 0.000</td> <td>    5.475</td> <td>   10.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(center(Defense))</th> <td>    2.9496</td> <td>    1.340</td> <td>    2.201</td> <td> 0.028</td> <td>    0.315</td> <td>    5.585</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    1.66</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}         &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}                &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}                  & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}                  &     23:26:55     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:}      &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}          &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}              &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}       &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}              &      69.3025  &        1.186     &    58.439  &         0.000        &       66.971    &       71.634     \\\\\n",
       "\\textbf{scale(center(Attack))}  &       8.1099  &        1.340     &     6.051  &         0.000        &        5.475    &       10.745     \\\\\n",
       "\\textbf{scale(center(Defense))} &       2.9496  &        1.340     &     2.201  &         0.028        &        0.315    &        5.585     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     1.66  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        23:26:55   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "Intercept                 69.3025      1.186     58.439      0.000      66.971      71.634\n",
       "scale(center(Attack))      8.1099      1.340      6.051      0.000       5.475      10.745\n",
       "scale(center(Defense))     2.9496      1.340      2.201      0.028       0.315       5.585\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         1.66\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from patsy import center, scale\n",
    "\n",
    "model3_linear_form_center_scale = \\\n",
    "  'HP ~ scale(center(Attack)) + scale(center(Defense))' \n",
    "model_spec3_center_scale = smf.ols(formula=model3_linear_form_center_scale,\n",
    "                                   data=pokeaman_train)\n",
    "model3_center_scale_fit = model_spec3_center_scale.fit()\n",
    "model3_center_scale_fit.summary()\n",
    "# \"Cond. No.\" is NOW 1.66 due to centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af15c9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.54e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.663  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.54e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_linear_form_CS = 'HP ~ scale(center(Attack)) * scale(center(Defense))'\n",
    "model4_linear_form_CS += ' * scale(center(Speed)) * Legendary' \n",
    "model4_linear_form_CS += ' * scale(center(Q(\"Sp. Def\"))) * scale(center(Q(\"Sp. Atk\")))'\n",
    "# Legendary is an indicator, so we don't center and scale that\n",
    "\n",
    "model4_CS_spec = smf.ols(formula=model4_linear_form_CS, data=pokeaman_train)\n",
    "model4_CS_fit = model4_CS_spec.fit()\n",
    "model4_CS_fit.summary().tables[-1]  # Cond. No. is 2,250,000,000,000,000\n",
    "\n",
    "# The condition number is still bad even after centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ebcb18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.20e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.664  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.20e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just as the condition number was very bad to start with\n",
    "model4_fit.summary().tables[-1]  # Cond. No. is 12,000,000,000,000,000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f4d0d3",
   "metadata": {},
   "source": [
    "### In the design matrix 'model4_spec.exog', the high correlation among predictor variables can be observed through 'np.corrcoef(model4_spec.exog)'. This multicollinearity leads to high instability in the estimated coefficients, making the model overly sensitive to random noise in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67f08d9",
   "metadata": {},
   "source": [
    "### The condition number for model 4 is extremely high (12,000,000,000,000,000 before centering and scaling, and still 2,250,000,000,000,000 after). This indicates a severe multicollinearity problem. The higher the condition number, the stronger the linear dependency in the design matrix, leading to increased uncertainty in the coefficient estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5092ae",
   "metadata": {},
   "source": [
    "### Evidence of generalization issues: Model 4 fits the training data very well but performs significantly worse on the test data. This is a typical sign of overfitting. The complexity of model 4 exceeds what the amount of data can support, causing incidental patterns in the training data to fail to replicate on the test data, indicating a clear lack of \"out-of-sample\" generalization in its predictive ability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcaa1b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfitting Issue: {'model': 'Model 4', 'issue': 'Overfitting due to high complexity', 'result': 'Poor out-of-sample generalization', 'cause': 'Detection of spurious patterns in training data'}\n",
      "Multicollinearity Issue: {'model': 'Model 4', 'issue': 'Multicollinearity in design matrix', 'result': 'Coefficient estimation instability and overfitting', 'generalization_problem': 'Model fails to generalize on new data'}\n",
      "Multicollinearity Solution: {'method': 'Centering and scaling predictors', 'benefit': 'Improves accuracy in assessing multicollinearity', 'diagnostic': 'Condition number remains high if multicollinearity is persistent', 'implication': 'Indicates potential generalization problems'}\n",
      "Generalization Explanation: \n",
      "Multicollinearity in Model 4’s design matrix causes overfitting by capturing specific \n",
      "training data patterns that do not hold up in new data, compromising generalization. \n",
      "High correlation among predictors makes coefficients sensitive to small data changes, \n",
      "leading to unstable and unreliable predictions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chat Summary\n",
    "\n",
    "# 1. Overfitting Issue in Model 4:\n",
    "# Model 4 is overly complex relative to the dataset size, leading to overfitting.\n",
    "# The model detects spurious patterns in the training data, causing poor \"out-of-sample\" generalization.\n",
    "\n",
    "overfitting_issue = {\n",
    "    \"model\": \"Model 4\",\n",
    "    \"issue\": \"Overfitting due to high complexity\",\n",
    "    \"result\": \"Poor out-of-sample generalization\",\n",
    "    \"cause\": \"Detection of spurious patterns in training data\"\n",
    "}\n",
    "\n",
    "# 2. Multicollinearity in Model 4’s Design Matrix:\n",
    "# High correlation among predictors in the design matrix creates instability in coefficient estimation,\n",
    "# causing the model to overfit specific patterns in the training data that don't generalize well to new data.\n",
    "\n",
    "multicollinearity_issue = {\n",
    "    \"model\": \"Model 4\",\n",
    "    \"issue\": \"Multicollinearity in design matrix\",\n",
    "    \"result\": \"Coefficient estimation instability and overfitting\",\n",
    "    \"generalization_problem\": \"Model fails to generalize on new data\"\n",
    "}\n",
    "\n",
    "# 3. Solution with Centering and Scaling Predictors:\n",
    "# Centering and scaling predictors provides a more accurate assessment of multicollinearity\n",
    "# using the condition number. A high condition number post-centering and scaling suggests\n",
    "# persistent multicollinearity, indicating generalization issues.\n",
    "\n",
    "multicollinearity_solution = {\n",
    "    \"method\": \"Centering and scaling predictors\",\n",
    "    \"benefit\": \"Improves accuracy in assessing multicollinearity\",\n",
    "    \"diagnostic\": \"Condition number remains high if multicollinearity is persistent\",\n",
    "    \"implication\": \"Indicates potential generalization problems\"\n",
    "}\n",
    "\n",
    "# Final explanation of inadequate generalization due to multicollinearity:\n",
    "generalization_explanation = \"\"\"\n",
    "Multicollinearity in Model 4’s design matrix causes overfitting by capturing specific \n",
    "training data patterns that do not hold up in new data, compromising generalization. \n",
    "High correlation among predictors makes coefficients sensitive to small data changes, \n",
    "leading to unstable and unreliable predictions.\n",
    "\"\"\"\n",
    "\n",
    "# Print summary for reference\n",
    "print(\"Overfitting Issue:\", overfitting_issue)\n",
    "print(\"Multicollinearity Issue:\", multicollinearity_issue)\n",
    "print(\"Multicollinearity Solution:\", multicollinearity_solution)\n",
    "print(\"Generalization Explanation:\", generalization_explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa36f800",
   "metadata": {},
   "source": [
    "link with ChatGPT: https://chatgpt.com/share/673688da-4ddc-800d-98ef-bff98855f6dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a51bfa",
   "metadata": {},
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ede79d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>9.48e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:38:52</td>     <th>  Log-Likelihood:    </th> <td> -1765.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3624.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   353</td>      <th>  BIC:               </th> <td>   3812.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    46</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td>   10.1046</td> <td>   14.957</td> <td>    0.676</td> <td> 0.500</td> <td>  -19.312</td> <td>   39.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>          <td>   -3.2717</td> <td>    4.943</td> <td>   -0.662</td> <td> 0.508</td> <td>  -12.992</td> <td>    6.449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>         <td>    9.2938</td> <td>    4.015</td> <td>    2.315</td> <td> 0.021</td> <td>    1.398</td> <td>   17.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>         <td>    2.3150</td> <td>    3.915</td> <td>    0.591</td> <td> 0.555</td> <td>   -5.385</td> <td>   10.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>         <td>    4.8353</td> <td>    4.149</td> <td>    1.165</td> <td> 0.245</td> <td>   -3.325</td> <td>   12.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>         <td>   11.4838</td> <td>    3.960</td> <td>    2.900</td> <td> 0.004</td> <td>    3.696</td> <td>   19.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>         <td>    4.9206</td> <td>    4.746</td> <td>    1.037</td> <td> 0.300</td> <td>   -4.413</td> <td>   14.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Dark]</th>     <td>   -1.4155</td> <td>    6.936</td> <td>   -0.204</td> <td> 0.838</td> <td>  -15.057</td> <td>   12.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Dragon]</th>   <td>    0.8509</td> <td>    6.900</td> <td>    0.123</td> <td> 0.902</td> <td>  -12.720</td> <td>   14.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Electric]</th> <td>   -6.3641</td> <td>    6.537</td> <td>   -0.974</td> <td> 0.331</td> <td>  -19.220</td> <td>    6.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fairy]</th>    <td>   -1.9486</td> <td>   10.124</td> <td>   -0.192</td> <td> 0.847</td> <td>  -21.859</td> <td>   17.962</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fighting]</th> <td>    7.0308</td> <td>    7.432</td> <td>    0.946</td> <td> 0.345</td> <td>   -7.586</td> <td>   21.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fire]</th>     <td>    3.0779</td> <td>    6.677</td> <td>    0.461</td> <td> 0.645</td> <td>  -10.055</td> <td>   16.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Flying]</th>   <td>   -2.1231</td> <td>   22.322</td> <td>   -0.095</td> <td> 0.924</td> <td>  -46.025</td> <td>   41.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ghost]</th>    <td>    5.7343</td> <td>    8.488</td> <td>    0.676</td> <td> 0.500</td> <td>  -10.960</td> <td>   22.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Grass]</th>    <td>    3.3275</td> <td>    5.496</td> <td>    0.605</td> <td> 0.545</td> <td>   -7.481</td> <td>   14.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ground]</th>   <td>    9.5118</td> <td>    7.076</td> <td>    1.344</td> <td> 0.180</td> <td>   -4.404</td> <td>   23.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ice]</th>      <td>   -0.9313</td> <td>    7.717</td> <td>   -0.121</td> <td> 0.904</td> <td>  -16.108</td> <td>   14.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Normal]</th>   <td>   18.4816</td> <td>    5.312</td> <td>    3.479</td> <td> 0.001</td> <td>    8.034</td> <td>   28.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Poison]</th>   <td>    8.3411</td> <td>    7.735</td> <td>    1.078</td> <td> 0.282</td> <td>   -6.871</td> <td>   23.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Psychic]</th>  <td>    1.8061</td> <td>    6.164</td> <td>    0.293</td> <td> 0.770</td> <td>  -10.317</td> <td>   13.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Rock]</th>     <td>   -3.8558</td> <td>    6.503</td> <td>   -0.593</td> <td> 0.554</td> <td>  -16.645</td> <td>    8.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Steel]</th>    <td>   -4.0053</td> <td>    8.044</td> <td>   -0.498</td> <td> 0.619</td> <td>  -19.826</td> <td>   11.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Water]</th>    <td>    9.7988</td> <td>    5.166</td> <td>    1.897</td> <td> 0.059</td> <td>   -0.361</td> <td>   19.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Dark]</th>     <td>    5.8719</td> <td>   15.185</td> <td>    0.387</td> <td> 0.699</td> <td>  -23.993</td> <td>   35.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Dragon]</th>   <td>   13.2777</td> <td>   14.895</td> <td>    0.891</td> <td> 0.373</td> <td>  -16.016</td> <td>   42.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Electric]</th> <td>   14.3228</td> <td>   17.314</td> <td>    0.827</td> <td> 0.409</td> <td>  -19.728</td> <td>   48.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fairy]</th>    <td>    2.8426</td> <td>   14.268</td> <td>    0.199</td> <td> 0.842</td> <td>  -25.218</td> <td>   30.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fighting]</th> <td>    1.9741</td> <td>   14.089</td> <td>    0.140</td> <td> 0.889</td> <td>  -25.735</td> <td>   29.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fire]</th>     <td>    0.2001</td> <td>   15.730</td> <td>    0.013</td> <td> 0.990</td> <td>  -30.736</td> <td>   31.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Flying]</th>   <td>    6.7292</td> <td>   13.581</td> <td>    0.495</td> <td> 0.621</td> <td>  -19.980</td> <td>   33.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ghost]</th>    <td>  -10.9402</td> <td>   15.895</td> <td>   -0.688</td> <td> 0.492</td> <td>  -42.201</td> <td>   20.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Grass]</th>    <td>    2.5119</td> <td>   14.540</td> <td>    0.173</td> <td> 0.863</td> <td>  -26.084</td> <td>   31.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ground]</th>   <td>   13.6042</td> <td>   13.655</td> <td>    0.996</td> <td> 0.320</td> <td>  -13.250</td> <td>   40.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ice]</th>      <td>   19.7950</td> <td>   15.068</td> <td>    1.314</td> <td> 0.190</td> <td>   -9.840</td> <td>   49.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.None]</th>     <td>    7.6068</td> <td>   13.162</td> <td>    0.578</td> <td> 0.564</td> <td>  -18.279</td> <td>   33.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Normal]</th>   <td>   17.3191</td> <td>   17.764</td> <td>    0.975</td> <td> 0.330</td> <td>  -17.618</td> <td>   52.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Poison]</th>   <td>    0.7770</td> <td>   14.575</td> <td>    0.053</td> <td> 0.958</td> <td>  -27.887</td> <td>   29.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Psychic]</th>  <td>    4.2480</td> <td>   14.174</td> <td>    0.300</td> <td> 0.765</td> <td>  -23.628</td> <td>   32.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Rock]</th>     <td>    6.8858</td> <td>   16.221</td> <td>    0.424</td> <td> 0.671</td> <td>  -25.017</td> <td>   38.788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Steel]</th>    <td>  -11.9623</td> <td>   14.973</td> <td>   -0.799</td> <td> 0.425</td> <td>  -41.409</td> <td>   17.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Water]</th>    <td>    5.8097</td> <td>   14.763</td> <td>    0.394</td> <td> 0.694</td> <td>  -23.225</td> <td>   34.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                     <td>    0.2508</td> <td>    0.051</td> <td>    4.940</td> <td> 0.000</td> <td>    0.151</td> <td>    0.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                    <td>   -0.0096</td> <td>    0.060</td> <td>   -0.160</td> <td> 0.873</td> <td>   -0.127</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                      <td>   -0.1538</td> <td>    0.051</td> <td>   -2.998</td> <td> 0.003</td> <td>   -0.255</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>               <td>    0.3484</td> <td>    0.059</td> <td>    5.936</td> <td> 0.000</td> <td>    0.233</td> <td>    0.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>               <td>    0.1298</td> <td>    0.051</td> <td>    2.525</td> <td> 0.012</td> <td>    0.029</td> <td>    0.231</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>286.476</td> <th>  Durbin-Watson:     </th> <td>   1.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5187.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.807</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>19.725</td>  <th>  Cond. No.          </th> <td>9.21e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 9.21e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}             &        HP        & \\textbf{  R-squared:         } &     0.392   \\\\\n",
       "\\textbf{Model:}                     &       OLS        & \\textbf{  Adj. R-squared:    } &     0.313   \\\\\n",
       "\\textbf{Method:}                    &  Least Squares   & \\textbf{  F-statistic:       } &     4.948   \\\\\n",
       "\\textbf{Date:}                      & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  9.48e-19   \\\\\n",
       "\\textbf{Time:}                      &     23:38:52     & \\textbf{  Log-Likelihood:    } &   -1765.0   \\\\\n",
       "\\textbf{No. Observations:}          &         400      & \\textbf{  AIC:               } &     3624.   \\\\\n",
       "\\textbf{Df Residuals:}              &         353      & \\textbf{  BIC:               } &     3812.   \\\\\n",
       "\\textbf{Df Model:}                  &          46      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}           &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                    & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                  &      10.1046  &       14.957     &     0.676  &         0.500        &      -19.312    &       39.521     \\\\\n",
       "\\textbf{Legendary[T.True]}          &      -3.2717  &        4.943     &    -0.662  &         0.508        &      -12.992    &        6.449     \\\\\n",
       "\\textbf{C(Generation)[T.2]}         &       9.2938  &        4.015     &     2.315  &         0.021        &        1.398    &       17.189     \\\\\n",
       "\\textbf{C(Generation)[T.3]}         &       2.3150  &        3.915     &     0.591  &         0.555        &       -5.385    &       10.015     \\\\\n",
       "\\textbf{C(Generation)[T.4]}         &       4.8353  &        4.149     &     1.165  &         0.245        &       -3.325    &       12.995     \\\\\n",
       "\\textbf{C(Generation)[T.5]}         &      11.4838  &        3.960     &     2.900  &         0.004        &        3.696    &       19.272     \\\\\n",
       "\\textbf{C(Generation)[T.6]}         &       4.9206  &        4.746     &     1.037  &         0.300        &       -4.413    &       14.254     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Dark]}     &      -1.4155  &        6.936     &    -0.204  &         0.838        &      -15.057    &       12.226     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Dragon]}   &       0.8509  &        6.900     &     0.123  &         0.902        &      -12.720    &       14.422     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Electric]} &      -6.3641  &        6.537     &    -0.974  &         0.331        &      -19.220    &        6.491     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fairy]}    &      -1.9486  &       10.124     &    -0.192  &         0.847        &      -21.859    &       17.962     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fighting]} &       7.0308  &        7.432     &     0.946  &         0.345        &       -7.586    &       21.648     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fire]}     &       3.0779  &        6.677     &     0.461  &         0.645        &      -10.055    &       16.210     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Flying]}   &      -2.1231  &       22.322     &    -0.095  &         0.924        &      -46.025    &       41.779     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ghost]}    &       5.7343  &        8.488     &     0.676  &         0.500        &      -10.960    &       22.429     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Grass]}    &       3.3275  &        5.496     &     0.605  &         0.545        &       -7.481    &       14.136     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ground]}   &       9.5118  &        7.076     &     1.344  &         0.180        &       -4.404    &       23.428     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ice]}      &      -0.9313  &        7.717     &    -0.121  &         0.904        &      -16.108    &       14.246     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Normal]}   &      18.4816  &        5.312     &     3.479  &         0.001        &        8.034    &       28.929     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Poison]}   &       8.3411  &        7.735     &     1.078  &         0.282        &       -6.871    &       23.554     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Psychic]}  &       1.8061  &        6.164     &     0.293  &         0.770        &      -10.317    &       13.930     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Rock]}     &      -3.8558  &        6.503     &    -0.593  &         0.554        &      -16.645    &        8.933     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Steel]}    &      -4.0053  &        8.044     &    -0.498  &         0.619        &      -19.826    &       11.816     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Water]}    &       9.7988  &        5.166     &     1.897  &         0.059        &       -0.361    &       19.959     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Dark]}     &       5.8719  &       15.185     &     0.387  &         0.699        &      -23.993    &       35.737     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Dragon]}   &      13.2777  &       14.895     &     0.891  &         0.373        &      -16.016    &       42.571     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Electric]} &      14.3228  &       17.314     &     0.827  &         0.409        &      -19.728    &       48.374     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fairy]}    &       2.8426  &       14.268     &     0.199  &         0.842        &      -25.218    &       30.903     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fighting]} &       1.9741  &       14.089     &     0.140  &         0.889        &      -25.735    &       29.683     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fire]}     &       0.2001  &       15.730     &     0.013  &         0.990        &      -30.736    &       31.136     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Flying]}   &       6.7292  &       13.581     &     0.495  &         0.621        &      -19.980    &       33.438     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ghost]}    &     -10.9402  &       15.895     &    -0.688  &         0.492        &      -42.201    &       20.321     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Grass]}    &       2.5119  &       14.540     &     0.173  &         0.863        &      -26.084    &       31.108     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ground]}   &      13.6042  &       13.655     &     0.996  &         0.320        &      -13.250    &       40.459     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ice]}      &      19.7950  &       15.068     &     1.314  &         0.190        &       -9.840    &       49.430     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.None]}     &       7.6068  &       13.162     &     0.578  &         0.564        &      -18.279    &       33.493     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Normal]}   &      17.3191  &       17.764     &     0.975  &         0.330        &      -17.618    &       52.256     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Poison]}   &       0.7770  &       14.575     &     0.053  &         0.958        &      -27.887    &       29.441     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Psychic]}  &       4.2480  &       14.174     &     0.300  &         0.765        &      -23.628    &       32.124     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Rock]}     &       6.8858  &       16.221     &     0.424  &         0.671        &      -25.017    &       38.788     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Steel]}    &     -11.9623  &       14.973     &    -0.799  &         0.425        &      -41.409    &       17.485     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Water]}    &       5.8097  &       14.763     &     0.394  &         0.694        &      -23.225    &       34.845     \\\\\n",
       "\\textbf{Attack}                     &       0.2508  &        0.051     &     4.940  &         0.000        &        0.151    &        0.351     \\\\\n",
       "\\textbf{Defense}                    &      -0.0096  &        0.060     &    -0.160  &         0.873        &       -0.127    &        0.108     \\\\\n",
       "\\textbf{Speed}                      &      -0.1538  &        0.051     &    -2.998  &         0.003        &       -0.255    &       -0.053     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}               &       0.3484  &        0.059     &     5.936  &         0.000        &        0.233    &        0.464     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}               &       0.1298  &        0.051     &     2.525  &         0.012        &        0.029    &        0.231     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 286.476 & \\textbf{  Durbin-Watson:     } &    1.917  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5187.327  \\\\\n",
       "\\textbf{Skew:}          &   2.807 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  19.725 & \\textbf{  Cond. No.          } & 9.21e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 9.21e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.392\n",
       "Model:                            OLS   Adj. R-squared:                  0.313\n",
       "Method:                 Least Squares   F-statistic:                     4.948\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           9.48e-19\n",
       "Time:                        23:38:52   Log-Likelihood:                -1765.0\n",
       "No. Observations:                 400   AIC:                             3624.\n",
       "Df Residuals:                     353   BIC:                             3812.\n",
       "Df Model:                          46                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Intercept                     10.1046     14.957      0.676      0.500     -19.312      39.521\n",
       "Legendary[T.True]             -3.2717      4.943     -0.662      0.508     -12.992       6.449\n",
       "C(Generation)[T.2]             9.2938      4.015      2.315      0.021       1.398      17.189\n",
       "C(Generation)[T.3]             2.3150      3.915      0.591      0.555      -5.385      10.015\n",
       "C(Generation)[T.4]             4.8353      4.149      1.165      0.245      -3.325      12.995\n",
       "C(Generation)[T.5]            11.4838      3.960      2.900      0.004       3.696      19.272\n",
       "C(Generation)[T.6]             4.9206      4.746      1.037      0.300      -4.413      14.254\n",
       "C(Q(\"Type 1\"))[T.Dark]        -1.4155      6.936     -0.204      0.838     -15.057      12.226\n",
       "C(Q(\"Type 1\"))[T.Dragon]       0.8509      6.900      0.123      0.902     -12.720      14.422\n",
       "C(Q(\"Type 1\"))[T.Electric]    -6.3641      6.537     -0.974      0.331     -19.220       6.491\n",
       "C(Q(\"Type 1\"))[T.Fairy]       -1.9486     10.124     -0.192      0.847     -21.859      17.962\n",
       "C(Q(\"Type 1\"))[T.Fighting]     7.0308      7.432      0.946      0.345      -7.586      21.648\n",
       "C(Q(\"Type 1\"))[T.Fire]         3.0779      6.677      0.461      0.645     -10.055      16.210\n",
       "C(Q(\"Type 1\"))[T.Flying]      -2.1231     22.322     -0.095      0.924     -46.025      41.779\n",
       "C(Q(\"Type 1\"))[T.Ghost]        5.7343      8.488      0.676      0.500     -10.960      22.429\n",
       "C(Q(\"Type 1\"))[T.Grass]        3.3275      5.496      0.605      0.545      -7.481      14.136\n",
       "C(Q(\"Type 1\"))[T.Ground]       9.5118      7.076      1.344      0.180      -4.404      23.428\n",
       "C(Q(\"Type 1\"))[T.Ice]         -0.9313      7.717     -0.121      0.904     -16.108      14.246\n",
       "C(Q(\"Type 1\"))[T.Normal]      18.4816      5.312      3.479      0.001       8.034      28.929\n",
       "C(Q(\"Type 1\"))[T.Poison]       8.3411      7.735      1.078      0.282      -6.871      23.554\n",
       "C(Q(\"Type 1\"))[T.Psychic]      1.8061      6.164      0.293      0.770     -10.317      13.930\n",
       "C(Q(\"Type 1\"))[T.Rock]        -3.8558      6.503     -0.593      0.554     -16.645       8.933\n",
       "C(Q(\"Type 1\"))[T.Steel]       -4.0053      8.044     -0.498      0.619     -19.826      11.816\n",
       "C(Q(\"Type 1\"))[T.Water]        9.7988      5.166      1.897      0.059      -0.361      19.959\n",
       "C(Q(\"Type 2\"))[T.Dark]         5.8719     15.185      0.387      0.699     -23.993      35.737\n",
       "C(Q(\"Type 2\"))[T.Dragon]      13.2777     14.895      0.891      0.373     -16.016      42.571\n",
       "C(Q(\"Type 2\"))[T.Electric]    14.3228     17.314      0.827      0.409     -19.728      48.374\n",
       "C(Q(\"Type 2\"))[T.Fairy]        2.8426     14.268      0.199      0.842     -25.218      30.903\n",
       "C(Q(\"Type 2\"))[T.Fighting]     1.9741     14.089      0.140      0.889     -25.735      29.683\n",
       "C(Q(\"Type 2\"))[T.Fire]         0.2001     15.730      0.013      0.990     -30.736      31.136\n",
       "C(Q(\"Type 2\"))[T.Flying]       6.7292     13.581      0.495      0.621     -19.980      33.438\n",
       "C(Q(\"Type 2\"))[T.Ghost]      -10.9402     15.895     -0.688      0.492     -42.201      20.321\n",
       "C(Q(\"Type 2\"))[T.Grass]        2.5119     14.540      0.173      0.863     -26.084      31.108\n",
       "C(Q(\"Type 2\"))[T.Ground]      13.6042     13.655      0.996      0.320     -13.250      40.459\n",
       "C(Q(\"Type 2\"))[T.Ice]         19.7950     15.068      1.314      0.190      -9.840      49.430\n",
       "C(Q(\"Type 2\"))[T.None]         7.6068     13.162      0.578      0.564     -18.279      33.493\n",
       "C(Q(\"Type 2\"))[T.Normal]      17.3191     17.764      0.975      0.330     -17.618      52.256\n",
       "C(Q(\"Type 2\"))[T.Poison]       0.7770     14.575      0.053      0.958     -27.887      29.441\n",
       "C(Q(\"Type 2\"))[T.Psychic]      4.2480     14.174      0.300      0.765     -23.628      32.124\n",
       "C(Q(\"Type 2\"))[T.Rock]         6.8858     16.221      0.424      0.671     -25.017      38.788\n",
       "C(Q(\"Type 2\"))[T.Steel]      -11.9623     14.973     -0.799      0.425     -41.409      17.485\n",
       "C(Q(\"Type 2\"))[T.Water]        5.8097     14.763      0.394      0.694     -23.225      34.845\n",
       "Attack                         0.2508      0.051      4.940      0.000       0.151       0.351\n",
       "Defense                       -0.0096      0.060     -0.160      0.873      -0.127       0.108\n",
       "Speed                         -0.1538      0.051     -2.998      0.003      -0.255      -0.053\n",
       "Q(\"Sp. Def\")                   0.3484      0.059      5.936      0.000       0.233       0.464\n",
       "Q(\"Sp. Atk\")                   0.1298      0.051      2.525      0.012       0.029       0.231\n",
       "==============================================================================\n",
       "Omnibus:                      286.476   Durbin-Watson:                   1.917\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5187.327\n",
       "Skew:                           2.807   Prob(JB):                         0.00\n",
       "Kurtosis:                      19.725   Cond. No.                     9.21e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 9.21e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's something a little more reasonable...\n",
    "model5_linear_form = 'HP ~ Attack + Defense + Speed + Legendary'\n",
    "model5_linear_form += ' + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "model5_linear_form += ' + C(Generation) + C(Q(\"Type 1\")) + C(Q(\"Type 2\"))'\n",
    "\n",
    "model5_spec = smf.ols(formula=model5_linear_form, data=pokeaman_train)\n",
    "model5_fit = model5_spec.fit()\n",
    "model5_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e308ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3920134083531893\n",
      "'Out of sample' R-squared: 0.30015614488652215\n"
     ]
    }
   ],
   "source": [
    "yhat_model5 = model5_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model5_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model5)[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e0230d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   24.36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>2.25e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:39:13</td>     <th>  Log-Likelihood:    </th> <td> -1783.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3585.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   391</td>      <th>  BIC:               </th> <td>   3621.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                   <td></td>                     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                          <td>   22.8587</td> <td>    3.876</td> <td>    5.897</td> <td> 0.000</td> <td>   15.238</td> <td>   30.479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Normal\")[T.True]</th> <td>   17.5594</td> <td>    3.339</td> <td>    5.258</td> <td> 0.000</td> <td>   10.994</td> <td>   24.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Water\")[T.True]</th>  <td>    9.0301</td> <td>    3.172</td> <td>    2.847</td> <td> 0.005</td> <td>    2.794</td> <td>   15.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 2)[T.True]</th>         <td>    6.5293</td> <td>    2.949</td> <td>    2.214</td> <td> 0.027</td> <td>    0.732</td> <td>   12.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 5)[T.True]</th>         <td>    8.4406</td> <td>    2.711</td> <td>    3.114</td> <td> 0.002</td> <td>    3.112</td> <td>   13.770</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                             <td>    0.2454</td> <td>    0.037</td> <td>    6.639</td> <td> 0.000</td> <td>    0.173</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                              <td>   -0.1370</td> <td>    0.045</td> <td>   -3.028</td> <td> 0.003</td> <td>   -0.226</td> <td>   -0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                       <td>    0.3002</td> <td>    0.045</td> <td>    6.662</td> <td> 0.000</td> <td>    0.212</td> <td>    0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                       <td>    0.1192</td> <td>    0.042</td> <td>    2.828</td> <td> 0.005</td> <td>    0.036</td> <td>    0.202</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>271.290</td> <th>  Durbin-Watson:     </th> <td>   1.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4238.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.651</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>18.040</td>  <th>  Cond. No.          </th> <td>    618.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                     &        HP        & \\textbf{  R-squared:         } &     0.333   \\\\\n",
       "\\textbf{Model:}                             &       OLS        & \\textbf{  Adj. R-squared:    } &     0.319   \\\\\n",
       "\\textbf{Method:}                            &  Least Squares   & \\textbf{  F-statistic:       } &     24.36   \\\\\n",
       "\\textbf{Date:}                              & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  2.25e-30   \\\\\n",
       "\\textbf{Time:}                              &     23:39:13     & \\textbf{  Log-Likelihood:    } &   -1783.6   \\\\\n",
       "\\textbf{No. Observations:}                  &         400      & \\textbf{  AIC:               } &     3585.   \\\\\n",
       "\\textbf{Df Residuals:}                      &         391      & \\textbf{  BIC:               } &     3621.   \\\\\n",
       "\\textbf{Df Model:}                          &           8      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                   &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                            & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                          &      22.8587  &        3.876     &     5.897  &         0.000        &       15.238    &       30.479     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Normal\")[T.True]} &      17.5594  &        3.339     &     5.258  &         0.000        &       10.994    &       24.125     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Water\")[T.True]}  &       9.0301  &        3.172     &     2.847  &         0.005        &        2.794    &       15.266     \\\\\n",
       "\\textbf{I(Generation == 2)[T.True]}         &       6.5293  &        2.949     &     2.214  &         0.027        &        0.732    &       12.327     \\\\\n",
       "\\textbf{I(Generation == 5)[T.True]}         &       8.4406  &        2.711     &     3.114  &         0.002        &        3.112    &       13.770     \\\\\n",
       "\\textbf{Attack}                             &       0.2454  &        0.037     &     6.639  &         0.000        &        0.173    &        0.318     \\\\\n",
       "\\textbf{Speed}                              &      -0.1370  &        0.045     &    -3.028  &         0.003        &       -0.226    &       -0.048     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                       &       0.3002  &        0.045     &     6.662  &         0.000        &        0.212    &        0.389     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                       &       0.1192  &        0.042     &     2.828  &         0.005        &        0.036    &        0.202     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 271.290 & \\textbf{  Durbin-Watson:     } &    1.999  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 4238.692  \\\\\n",
       "\\textbf{Skew:}          &   2.651 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  18.040 & \\textbf{  Cond. No.          } &     618.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.333\n",
       "Model:                            OLS   Adj. R-squared:                  0.319\n",
       "Method:                 Least Squares   F-statistic:                     24.36\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           2.25e-30\n",
       "Time:                        23:39:13   Log-Likelihood:                -1783.6\n",
       "No. Observations:                 400   AIC:                             3585.\n",
       "Df Residuals:                     391   BIC:                             3621.\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================================\n",
       "                                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------\n",
       "Intercept                             22.8587      3.876      5.897      0.000      15.238      30.479\n",
       "I(Q(\"Type 1\") == \"Normal\")[T.True]    17.5594      3.339      5.258      0.000      10.994      24.125\n",
       "I(Q(\"Type 1\") == \"Water\")[T.True]      9.0301      3.172      2.847      0.005       2.794      15.266\n",
       "I(Generation == 2)[T.True]             6.5293      2.949      2.214      0.027       0.732      12.327\n",
       "I(Generation == 5)[T.True]             8.4406      2.711      3.114      0.002       3.112      13.770\n",
       "Attack                                 0.2454      0.037      6.639      0.000       0.173       0.318\n",
       "Speed                                 -0.1370      0.045     -3.028      0.003      -0.226      -0.048\n",
       "Q(\"Sp. Def\")                           0.3002      0.045      6.662      0.000       0.212       0.389\n",
       "Q(\"Sp. Atk\")                           0.1192      0.042      2.828      0.005       0.036       0.202\n",
       "==============================================================================\n",
       "Omnibus:                      271.290   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4238.692\n",
       "Skew:                           2.651   Prob(JB):                         0.00\n",
       "Kurtosis:                      18.040   Cond. No.                         618.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's something a little more reasonable...\n",
    "model6_linear_form = 'HP ~ Attack + Speed + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "# And here we'll add the significant indicators from the previous model\n",
    "# https://chatgpt.com/share/81ab88df-4f07-49f9-a44a-de0cfd89c67c\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model6_linear_form += ' + I(Generation==2)'\n",
    "model6_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model6_spec = smf.ols(formula=model6_linear_form, data=pokeaman_train)\n",
    "model6_fit = model6_spec.fit()\n",
    "model6_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e2d1c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908\n",
      "'Out of sample' R-squared: 0.29572460427079933\n"
     ]
    }
   ],
   "source": [
    "yhat_model6 = model6_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6dc9e237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>4.20e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:41:16</td>     <th>  Log-Likelihood:    </th> <td> -1769.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3579.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   380</td>      <th>  BIC:               </th> <td>   3659.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                     <td></td>                       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                              <td>   95.1698</td> <td>   34.781</td> <td>    2.736</td> <td> 0.007</td> <td>   26.783</td> <td>  163.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Normal\")[T.True]</th>     <td>   18.3653</td> <td>    3.373</td> <td>    5.445</td> <td> 0.000</td> <td>   11.733</td> <td>   24.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Water\")[T.True]</th>      <td>    9.2913</td> <td>    3.140</td> <td>    2.959</td> <td> 0.003</td> <td>    3.117</td> <td>   15.466</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 2)[T.True]</th>             <td>    7.0711</td> <td>    2.950</td> <td>    2.397</td> <td> 0.017</td> <td>    1.271</td> <td>   12.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 5)[T.True]</th>             <td>    7.8557</td> <td>    2.687</td> <td>    2.923</td> <td> 0.004</td> <td>    2.572</td> <td>   13.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                 <td>   -0.6975</td> <td>    0.458</td> <td>   -1.523</td> <td> 0.129</td> <td>   -1.598</td> <td>    0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                                  <td>   -1.8147</td> <td>    0.554</td> <td>   -3.274</td> <td> 0.001</td> <td>   -2.905</td> <td>   -0.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed</th>                           <td>    0.0189</td> <td>    0.007</td> <td>    2.882</td> <td> 0.004</td> <td>    0.006</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                           <td>   -0.5532</td> <td>    0.546</td> <td>   -1.013</td> <td> 0.312</td> <td>   -1.627</td> <td>    0.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\")</th>                    <td>    0.0090</td> <td>    0.007</td> <td>    1.311</td> <td> 0.191</td> <td>   -0.004</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\")</th>                     <td>    0.0208</td> <td>    0.008</td> <td>    2.571</td> <td> 0.011</td> <td>    0.005</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\")</th>              <td>   -0.0002</td> <td> 9.06e-05</td> <td>   -2.277</td> <td> 0.023</td> <td>   -0.000</td> <td>-2.82e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                           <td>   -0.7277</td> <td>    0.506</td> <td>   -1.439</td> <td> 0.151</td> <td>   -1.722</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Atk\")</th>                    <td>    0.0136</td> <td>    0.005</td> <td>    2.682</td> <td> 0.008</td> <td>    0.004</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Atk\")</th>                     <td>    0.0146</td> <td>    0.007</td> <td>    2.139</td> <td> 0.033</td> <td>    0.001</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Atk\")</th>              <td>   -0.0002</td> <td>  5.4e-05</td> <td>   -3.383</td> <td> 0.001</td> <td>   -0.000</td> <td>-7.65e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>              <td>    0.0103</td> <td>    0.007</td> <td>    1.516</td> <td> 0.130</td> <td>   -0.003</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>       <td>   -0.0001</td> <td> 6.71e-05</td> <td>   -2.119</td> <td> 0.035</td> <td>   -0.000</td> <td>-1.03e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>        <td>   -0.0002</td> <td> 8.82e-05</td> <td>   -2.075</td> <td> 0.039</td> <td>   -0.000</td> <td>-9.62e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th> <td>  2.03e-06</td> <td> 7.42e-07</td> <td>    2.734</td> <td> 0.007</td> <td>  5.7e-07</td> <td> 3.49e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>2.34e+09</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.34e+09. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                         &        HP        & \\textbf{  R-squared:         } &     0.378   \\\\\n",
       "\\textbf{Model:}                                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.347   \\\\\n",
       "\\textbf{Method:}                                &  Least Squares   & \\textbf{  F-statistic:       } &     12.16   \\\\\n",
       "\\textbf{Date:}                                  & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  4.20e-29   \\\\\n",
       "\\textbf{Time:}                                  &     23:41:16     & \\textbf{  Log-Likelihood:    } &   -1769.5   \\\\\n",
       "\\textbf{No. Observations:}                      &         400      & \\textbf{  AIC:               } &     3579.   \\\\\n",
       "\\textbf{Df Residuals:}                          &         380      & \\textbf{  BIC:               } &     3659.   \\\\\n",
       "\\textbf{Df Model:}                              &          19      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                       &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                              &      95.1698  &       34.781     &     2.736  &         0.007        &       26.783    &      163.556     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Normal\")[T.True]}     &      18.3653  &        3.373     &     5.445  &         0.000        &       11.733    &       24.997     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Water\")[T.True]}      &       9.2913  &        3.140     &     2.959  &         0.003        &        3.117    &       15.466     \\\\\n",
       "\\textbf{I(Generation == 2)[T.True]}             &       7.0711  &        2.950     &     2.397  &         0.017        &        1.271    &       12.871     \\\\\n",
       "\\textbf{I(Generation == 5)[T.True]}             &       7.8557  &        2.687     &     2.923  &         0.004        &        2.572    &       13.140     \\\\\n",
       "\\textbf{Attack}                                 &      -0.6975  &        0.458     &    -1.523  &         0.129        &       -1.598    &        0.203     \\\\\n",
       "\\textbf{Speed}                                  &      -1.8147  &        0.554     &    -3.274  &         0.001        &       -2.905    &       -0.725     \\\\\n",
       "\\textbf{Attack:Speed}                           &       0.0189  &        0.007     &     2.882  &         0.004        &        0.006    &        0.032     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                           &      -0.5532  &        0.546     &    -1.013  &         0.312        &       -1.627    &        0.521     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\")}                    &       0.0090  &        0.007     &     1.311  &         0.191        &       -0.004    &        0.023     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\")}                     &       0.0208  &        0.008     &     2.571  &         0.011        &        0.005    &        0.037     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\")}              &      -0.0002  &     9.06e-05     &    -2.277  &         0.023        &       -0.000    &    -2.82e-05     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                           &      -0.7277  &        0.506     &    -1.439  &         0.151        &       -1.722    &        0.267     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Atk\")}                    &       0.0136  &        0.005     &     2.682  &         0.008        &        0.004    &        0.024     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Atk\")}                     &       0.0146  &        0.007     &     2.139  &         0.033        &        0.001    &        0.028     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Atk\")}              &      -0.0002  &      5.4e-05     &    -3.383  &         0.001        &       -0.000    &    -7.65e-05     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):Q(\"Sp. Atk\")}              &       0.0103  &        0.007     &     1.516  &         0.130        &       -0.003    &        0.024     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}       &      -0.0001  &     6.71e-05     &    -2.119  &         0.035        &       -0.000    &    -1.03e-05     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}        &      -0.0002  &     8.82e-05     &    -2.075  &         0.039        &       -0.000    &    -9.62e-06     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")} &     2.03e-06  &     7.42e-07     &     2.734  &         0.007        &      5.7e-07    &     3.49e-06     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } & 2.34e+09  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.34e+09. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.378\n",
       "Model:                            OLS   Adj. R-squared:                  0.347\n",
       "Method:                 Least Squares   F-statistic:                     12.16\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           4.20e-29\n",
       "Time:                        23:41:16   Log-Likelihood:                -1769.5\n",
       "No. Observations:                 400   AIC:                             3579.\n",
       "Df Residuals:                     380   BIC:                             3659.\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================================\n",
       "                                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------------\n",
       "Intercept                                 95.1698     34.781      2.736      0.007      26.783     163.556\n",
       "I(Q(\"Type 1\") == \"Normal\")[T.True]        18.3653      3.373      5.445      0.000      11.733      24.997\n",
       "I(Q(\"Type 1\") == \"Water\")[T.True]          9.2913      3.140      2.959      0.003       3.117      15.466\n",
       "I(Generation == 2)[T.True]                 7.0711      2.950      2.397      0.017       1.271      12.871\n",
       "I(Generation == 5)[T.True]                 7.8557      2.687      2.923      0.004       2.572      13.140\n",
       "Attack                                    -0.6975      0.458     -1.523      0.129      -1.598       0.203\n",
       "Speed                                     -1.8147      0.554     -3.274      0.001      -2.905      -0.725\n",
       "Attack:Speed                               0.0189      0.007      2.882      0.004       0.006       0.032\n",
       "Q(\"Sp. Def\")                              -0.5532      0.546     -1.013      0.312      -1.627       0.521\n",
       "Attack:Q(\"Sp. Def\")                        0.0090      0.007      1.311      0.191      -0.004       0.023\n",
       "Speed:Q(\"Sp. Def\")                         0.0208      0.008      2.571      0.011       0.005       0.037\n",
       "Attack:Speed:Q(\"Sp. Def\")                 -0.0002   9.06e-05     -2.277      0.023      -0.000   -2.82e-05\n",
       "Q(\"Sp. Atk\")                              -0.7277      0.506     -1.439      0.151      -1.722       0.267\n",
       "Attack:Q(\"Sp. Atk\")                        0.0136      0.005      2.682      0.008       0.004       0.024\n",
       "Speed:Q(\"Sp. Atk\")                         0.0146      0.007      2.139      0.033       0.001       0.028\n",
       "Attack:Speed:Q(\"Sp. Atk\")                 -0.0002    5.4e-05     -3.383      0.001      -0.000   -7.65e-05\n",
       "Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  0.0103      0.007      1.516      0.130      -0.003       0.024\n",
       "Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")          -0.0001   6.71e-05     -2.119      0.035      -0.000   -1.03e-05\n",
       "Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           -0.0002   8.82e-05     -2.075      0.039      -0.000   -9.62e-06\n",
       "Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")   2.03e-06   7.42e-07      2.734      0.007     5.7e-07    3.49e-06\n",
       "==============================================================================\n",
       "Omnibus:                      252.300   Durbin-Watson:                   1.953\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3474.611\n",
       "Skew:                           2.438   Prob(JB):                         0.00\n",
       "Kurtosis:                      16.590   Cond. No.                     2.34e+09\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.34e+09. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And here's a slight change that seems to perhaps improve prediction...\n",
    "model7_linear_form = 'HP ~ Attack * Speed * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form += ' + I(Generation==2)'\n",
    "model7_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model7_spec = smf.ols(formula=model7_linear_form, data=pokeaman_train)\n",
    "model7_fit = model7_spec.fit()\n",
    "model7_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37247645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456\n",
      "'Out of sample' R-squared: 0.35055389205977444\n"
     ]
    }
   ],
   "source": [
    "yhat_model7 = model7_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccb7a46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>    15.4</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } &     15.4  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And here's a slight change that seems to perhas improve prediction...\n",
    "model7_linear_form_CS = 'HP ~ scale(center(Attack)) * scale(center(Speed))'\n",
    "model7_linear_form_CS += ' * scale(center(Q(\"Sp. Def\"))) * scale(center(Q(\"Sp. Atk\")))'\n",
    "# We DO NOT center and scale indicator variables\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form_CS += ' + I(Generation==2)'\n",
    "model7_linear_form_CS += ' + I(Generation==5)'\n",
    "\n",
    "model7_CS_spec = smf.ols(formula=model7_linear_form_CS, data=pokeaman_train)\n",
    "model7_CS_fit = model7_CS_spec.fit()\n",
    "model7_CS_fit.summary().tables[-1] \n",
    "# \"Cond. No.\" is NOW 15.4 due to centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cf3611c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>2.34e+09</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } & 2.34e+09  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Cond. No.\" WAS 2,340,000,000 WITHOUT to centering and scaling\n",
    "model7_fit.summary().tables[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea5eae0",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405f915f",
   "metadata": {},
   "source": [
    "### It includes multiple variables (such as Attack, Defense, Speed, etc.) and categorical variables (such as Legendary and Generation). Results show an R-squared of 0.392, but the out-of-sample R-squared is only 0.300, indicating the model's performance declines on the test set. The condition number is 9210, suggesting potential multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e91871",
   "metadata": {},
   "source": [
    "## Model 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5888105",
   "metadata": {},
   "source": [
    "### Insignificant variables were removed, and more significant type and generation indicator variables were added. Although the R-squared slightly decreased to 0.333, the model is simpler and avoids unnecessary variables. The condition number significantly dropped to 618, indicating an improvement in multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abab6be7",
   "metadata": {},
   "source": [
    "## Model 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3960f2d",
   "metadata": {},
   "source": [
    "### Interaction terms among Attack, Speed, Sp. Def, and Sp. Atk were introduced. The R-squared increased to 0.378, with an out-of-sample R-squared of 0.351, indicating further improvement in generalization performance. The original condition number was 2.34e+09, showing severe multicollinearity issues, but after centering and scaling, the condition number dropped to 15.4, resolving the multicollinearity problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d7098c",
   "metadata": {},
   "source": [
    "### From model 5 to model 7, insignificant variables were gradually removed, interaction terms were added, and the condition number was reduced, enhancing the model's predictive performance. Finally, in model 7, centering and scaling fully addressed the multicollinearity issue, ensuring stronger generalizability of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c38a8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Summary on Model Development and Evaluation\n",
      "\n",
      "Model Development and Iterative Refinement:\n",
      "1. Model 5: Broad set of predictors including Attack, Defense, Speed, Legendary, Sp. Def, Sp. Atk, Generation, Type 1, and Type 2.\n",
      "2. Model 6: Simplified model with only the most impactful predictors from Model 5, focusing on significant levels of categorical variables.\n",
      "3. Model 7: Introduced complex interactions among Attack, Speed, Sp. Def, and Sp. Atk to capture nuanced relationships.\n",
      "   - Centered and Scaled version of Model 7 reduced multicollinearity, as indicated by a lower condition number.\n",
      "\n",
      "Condition Number Analysis for Multicollinearity:\n",
      "- Cutoffs provided: <10, <100, <1000 for determining severity of multicollinearity.\n",
      "- Centered and Scaled Model 7 had a condition number of 15.4, indicating multicollinearity is not a major issue.\n",
      "\n",
      "Evidence-Based Model Assessment:\n",
      "- Predictive associations assessed through hypothesis testing of coefficients and in-sample vs. out-of-sample R-squared metrics.\n",
      "- Underperforming models deemed 'underfit' if they fail to leverage predictive associations.\n",
      "\n",
      "Distinction Between Multicollinearity and Predictive Evidence:\n",
      "- Multicollinearity affects reliability of coefficient estimates.\n",
      "- Predictive evidence, the main goal of regression, is assessed separately to ensure generalizability.\n",
      "\n",
      "Summary:\n",
      "The chat covered how each model iteration was refined to improve predictive accuracy, minimize multicollinearity,\n",
      "and maximize generalizability by balancing complexity with interpretability.\n"
     ]
    }
   ],
   "source": [
    "# Chat Summary\n",
    "\n",
    "# Model Development and Iterative Refinement\n",
    "# 1. Model 5: Broad set of predictors including Attack, Defense, Speed, Legendary, Sp. Def, Sp. Atk, Generation, Type 1, and Type 2.\n",
    "# 2. Model 6: Simplified model with only the most impactful predictors from Model 5, focusing on significant levels of categorical variables.\n",
    "# 3. Model 7: Introduced complex interactions among Attack, Speed, Sp. Def, and Sp. Atk to capture nuanced relationships.\n",
    "#    - Centered and Scaled version of Model 7 reduced multicollinearity, as indicated by a lower condition number.\n",
    "\n",
    "# Condition Number Analysis for Multicollinearity\n",
    "# - Cutoffs provided: <10, <100, <1000 for determining severity of multicollinearity.\n",
    "# - Centered and Scaled Model 7 had a condition number of 15.4, indicating multicollinearity is not a major issue.\n",
    "\n",
    "# Evidence-Based Model Assessment\n",
    "# - Predictive associations assessed through hypothesis testing of coefficients and in-sample vs. out-of-sample R-squared metrics.\n",
    "# - Underperforming models deemed \"underfit\" if they fail to leverage predictive associations.\n",
    "\n",
    "# Distinction Between Multicollinearity and Predictive Evidence\n",
    "# - Multicollinearity affects reliability of coefficient estimates.\n",
    "# - Predictive evidence, the main goal of regression, is assessed separately to ensure generalizability.\n",
    "\n",
    "# Summary\n",
    "# The chat covered how each model iteration was refined to improve predictive accuracy, minimize multicollinearity,\n",
    "# and maximize generalizability by balancing complexity with interpretability.\n",
    "\n",
    "print(\"Chat Summary on Model Development and Evaluation\\n\")\n",
    "print(\"Model Development and Iterative Refinement:\")\n",
    "print(\"1. Model 5: Broad set of predictors including Attack, Defense, Speed, Legendary, Sp. Def, Sp. Atk, Generation, Type 1, and Type 2.\")\n",
    "print(\"2. Model 6: Simplified model with only the most impactful predictors from Model 5, focusing on significant levels of categorical variables.\")\n",
    "print(\"3. Model 7: Introduced complex interactions among Attack, Speed, Sp. Def, and Sp. Atk to capture nuanced relationships.\")\n",
    "print(\"   - Centered and Scaled version of Model 7 reduced multicollinearity, as indicated by a lower condition number.\\n\")\n",
    "\n",
    "print(\"Condition Number Analysis for Multicollinearity:\")\n",
    "print(\"- Cutoffs provided: <10, <100, <1000 for determining severity of multicollinearity.\")\n",
    "print(\"- Centered and Scaled Model 7 had a condition number of 15.4, indicating multicollinearity is not a major issue.\\n\")\n",
    "\n",
    "print(\"Evidence-Based Model Assessment:\")\n",
    "print(\"- Predictive associations assessed through hypothesis testing of coefficients and in-sample vs. out-of-sample R-squared metrics.\")\n",
    "print(\"- Underperforming models deemed 'underfit' if they fail to leverage predictive associations.\\n\")\n",
    "\n",
    "print(\"Distinction Between Multicollinearity and Predictive Evidence:\")\n",
    "print(\"- Multicollinearity affects reliability of coefficient estimates.\")\n",
    "print(\"- Predictive evidence, the main goal of regression, is assessed separately to ensure generalizability.\\n\")\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(\"The chat covered how each model iteration was refined to improve predictive accuracy, minimize multicollinearity,\")\n",
    "print(\"and maximize generalizability by balancing complexity with interpretability.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160317a2",
   "metadata": {},
   "source": [
    "link with ChatGPT: https://chatgpt.com/share/673691af-605c-800d-a4cc-a9e74bf0190e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6867652",
   "metadata": {},
   "source": [
    "# Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72be64a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Mock dataset for testing\n",
    "np.random.seed(0)\n",
    "songs = pd.DataFrame({\n",
    "    'danceability': np.random.rand(100),\n",
    "    'energy': np.random.rand(100),\n",
    "    'loudness': np.random.rand(100),\n",
    "    'mode': np.random.randint(0, 2, 100)\n",
    "})\n",
    "\n",
    "# Define linear model formula\n",
    "linear_form = 'danceability ~ energy * loudness + energy * mode'\n",
    "\n",
    "# Number of repetitions for re-splitting and evaluating the model\n",
    "reps = 100\n",
    "in_sample_Rsquared = np.array([0.0] * reps)\n",
    "out_of_sample_Rsquared = np.array([0.0] * reps)\n",
    "\n",
    "for i in range(reps):\n",
    "    # Randomly split data into training and testing sets\n",
    "    songs_training_data, songs_testing_data = train_test_split(songs, train_size=31)\n",
    "    \n",
    "    # Fit the model on the training set\n",
    "    final_model_fit = smf.ols(formula=linear_form, data=songs_training_data).fit()\n",
    "    \n",
    "    # Collect in-sample R-squared\n",
    "    in_sample_Rsquared[i] = final_model_fit.rsquared\n",
    "    \n",
    "    # Collect out-of-sample R-squared\n",
    "    out_of_sample_Rsquared[i] = np.corrcoef(\n",
    "        songs_testing_data.danceability,\n",
    "        final_model_fit.predict(songs_testing_data)\n",
    "    )[0, 1] ** 2\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "df = pd.DataFrame({\n",
    "    \"In Sample Performance (Rsquared)\": in_sample_Rsquared,\n",
    "    \"Out of Sample Performance (Rsquared)\": out_of_sample_Rsquared\n",
    "})\n",
    "\n",
    "# Scatter plot to visualize in-sample vs. out-of-sample R-squared values\n",
    "fig = px.scatter(df, x=\"In Sample Performance (Rsquared)\", \n",
    "                 y=\"Out of Sample Performance (Rsquared)\",\n",
    "                 title=\"In-Sample vs Out-of-Sample R-squared Performance\")\n",
    "# Add y=x reference line\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode=\"lines\", name=\"y=x\"))\n",
    "\n",
    "# Show plot\n",
    "fig.show(renderer=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da15db42",
   "metadata": {},
   "source": [
    "### The code repeatedly splits the dataset randomly, trains the model, and records in-sample and out-of-sample R-squared values to compare the model's performance. This experiment helps us evaluate the model's generalizability and stability, revealing its performance differences across various data splits. If there is a large discrepancy between in-sample and out-of-sample performance, it may suggest overfitting; whereas if the scatter plot points lie close to the y=x line, it indicates good generalizability. This approach aids in understanding the model's stability and in determining if its performance depends on specific training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3562e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Task Overview:\n",
      "   - You asked for assistance with creating a for-loop to collect and visualize in-sample and out-of-sample R-squared values without setting a fixed random seed, aiming to evaluate model consistency across different random train-test splits.\n",
      "\n",
      "2. Code Explanation:\n",
      "   - We wrote a for-loop that randomly splits data, trains a model, and records R-squared values for in-sample and out-of-sample performance across 100 iterations.\n",
      "   - The code uses train_test_split to split data, fits an OLS model, and then calculates R-squared values for each split. Results are stored in arrays and then visualized in a scatter plot.\n",
      "\n",
      "3. Results Explanation:\n",
      "   - In-sample R-squared measures model fit on training data, while out-of-sample R-squared indicates performance on unseen data.\n",
      "   - A scatter plot shows in-sample vs. out-of-sample R-squared values, with the y=x line as a benchmark. Points close to this line indicate similar performance on both data sets, while points far from it suggest potential overfitting or underfitting.\n",
      "\n",
      "4. Purpose of Demonstration:\n",
      "   - The exercise helps assess model stability and generalizability, indicating how well the model performs across varying data splits.\n",
      "   - The results provide insights into model overfitting, underfitting, and whether adjustments to the model structure might improve predictive consistency on unseen data.\n",
      "\n",
      "This approach allows you to evaluate the model's behavior under varying data splits, giving a clearer view of its potential for generalization.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chat Summary\n",
    "summary = \"\"\"\n",
    "1. Task Overview:\n",
    "   - You asked for assistance with creating a for-loop to collect and visualize in-sample and out-of-sample R-squared values without setting a fixed random seed, aiming to evaluate model consistency across different random train-test splits.\n",
    "\n",
    "2. Code Explanation:\n",
    "   - We wrote a for-loop that randomly splits data, trains a model, and records R-squared values for in-sample and out-of-sample performance across 100 iterations.\n",
    "   - The code uses train_test_split to split data, fits an OLS model, and then calculates R-squared values for each split. Results are stored in arrays and then visualized in a scatter plot.\n",
    "\n",
    "3. Results Explanation:\n",
    "   - In-sample R-squared measures model fit on training data, while out-of-sample R-squared indicates performance on unseen data.\n",
    "   - A scatter plot shows in-sample vs. out-of-sample R-squared values, with the y=x line as a benchmark. Points close to this line indicate similar performance on both data sets, while points far from it suggest potential overfitting or underfitting.\n",
    "\n",
    "4. Purpose of Demonstration:\n",
    "   - The exercise helps assess model stability and generalizability, indicating how well the model performs across varying data splits.\n",
    "   - The results provide insights into model overfitting, underfitting, and whether adjustments to the model structure might improve predictive consistency on unseen data.\n",
    "\n",
    "This approach allows you to evaluate the model's behavior under varying data splits, giving a clearer view of its potential for generalization.\n",
    "\"\"\"\n",
    "\n",
    "# Print summary for assignment or review\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a652afb",
   "metadata": {},
   "source": [
    "link with ChatGPT: https://chatgpt.com/share/673698b1-e2f8-800d-ae36-254a05540843"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc5dad0",
   "metadata": {},
   "source": [
    "# Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50e89be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456 (original)\n",
      "'Out of sample' R-squared: 0.35055389205977444 (original)\n",
      "'In sample' R-squared:     0.5726118179916575 (gen1_predict_future)\n",
      "'Out of sample' R-squared: 0.11151363354803218 (gen1_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model7_gen1_predict_future = smf.ols(formula=model7_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation==1])\n",
    "model7_gen1_predict_future_fit = model7_gen1_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model7_gen1_predict_future_fit.rsquared, \"(gen1_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation!=1].HP\n",
    "yhat = model7_gen1_predict_future_fit.predict(pokeaman[pokeaman.Generation!=1])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1_predict_future)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "edd0b5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456 (original)\n",
      "'Out of sample' R-squared: 0.35055389205977444 (original)\n",
      "'In sample' R-squared:     0.3904756578094535 (gen1to5_predict_future)\n",
      "'Out of sample' R-squared: 0.23394915464343125 (gen1to5_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model7_gen1to5_predict_future = smf.ols(formula=model7_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation!=6])\n",
    "model7_gen1to5_predict_future_fit = model7_gen1to5_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model7_gen1to5_predict_future_fit.rsquared, \"(gen1to5_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation==6].HP\n",
    "yhat = model7_gen1to5_predict_future_fit.predict(pokeaman[pokeaman.Generation==6])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1to5_predict_future)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4824fb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908 (original)\n",
      "'Out of sample' R-squared: 0.29572460427079933 (original)\n",
      "'In sample' R-squared:     0.4433880517727282 (gen1_predict_future)\n",
      "'Out of sample' R-squared: 0.1932858534276128 (gen1_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model6_gen1_predict_future = smf.ols(formula=model6_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation==1])\n",
    "model6_gen1_predict_future_fit = model6_gen1_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model6_gen1_predict_future_fit.rsquared, \"(gen1_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation!=1].HP\n",
    "yhat = model6_gen1_predict_future_fit.predict(pokeaman[pokeaman.Generation!=1])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1_predict_future)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b272acf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908 (original)\n",
      "'Out of sample' R-squared: 0.29572460427079933 (original)\n",
      "'In sample' R-squared:     0.33517279824114776 (gen1to5_predict_future)\n",
      "'Out of sample' R-squared: 0.26262690178799936 (gen1to5_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model6_gen1to5_predict_future = smf.ols(formula=model6_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation!=6])\n",
    "model6_gen1to5_predict_future_fit = model6_gen1to5_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model6_gen1to5_predict_future_fit.rsquared, \"(gen1to5_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation==6].HP\n",
    "yhat = model6_gen1to5_predict_future_fit.predict(pokeaman[pokeaman.Generation==6])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1to5_predict_future)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a41c6d",
   "metadata": {},
   "source": [
    "### Although 'model7_fit' demonstrated better \"out of sample\" predictive performance during training, its higher complexity—containing multiple high-order interaction terms—raises concerns about generalizability. This suggests that 'model7_fit' may detect some incidental associations within the training data, but fails to maintain the same performance on test data, resulting in less stable outcomes, especially when predicting future data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83931e7c",
   "metadata": {},
   "source": [
    "### While 'model6_fit' is slightly inferior to 'model7_fit' in \"out of sample\" performance, its simpler structure and fewer parameters offer greater interpretability. Compared to the complex interaction model, the parameters in a simpler model generally have clearer meanings, making the model more understandable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023a308a",
   "metadata": {},
   "source": [
    "### The steps in the code simulate a scenario where the model is trained on Generation 1 or Generation 1-5 data and then used to predict future data. This approach reveals that 'model7_fit' has poorer generalization performance when incrementally receiving new data. Especially when data arrives over time (simulating real-world predictive situations), 'model7_fit' shows lower \"out of sample\" R-squared values across different Generations, indicating a higher tendency to overfit and less stability compared to 'model6_fit'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fdc72f",
   "metadata": {},
   "source": [
    "### Although 'model7_fit' initially performed better in \"out of sample\" evaluation, its higher complexity and poorer generalizability make 'model6_fit' a preferable choice in practical applications. This is because overly complex models may capture specific patterns in the training data that result in poorer performance on new datasets. Therefore, in real-world scenarios, unless a more complex model offers a clear predictive advantage, a simpler and more interpretable model, such as 'model6_fit', is typically preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c90450c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Model Complexity and Generalizability:\n",
      "model7_fit is more complex with higher-order interactions but tends to overfit the training data, leading to poorer out-of-sample performance. model6_fit, though simpler, generalizes better across different generations.\n",
      "\n",
      "2. In-sample vs Out-of-sample Performance:\n",
      "Both models show similar in-sample R-squared values, meaning they fit the training data similarly. However, model7_fit shows a more significant drop in out-of-sample performance, indicating potential overfitting.\n",
      "\n",
      "3. Overfitting Concerns:\n",
      "The significant drop in out-of-sample performance for model7_fit when trained on specific generation data suggests it is overfitting the training data. model6_fit, being simpler, shows better generalizability.\n",
      "\n",
      "4. Model Interpretability:\n",
      "model6_fit is simpler and easier to interpret. Complex models like model7_fit, with many interactions, can be harder to understand and explain.\n",
      "\n",
      "5. Real-world Considerations and Conclusion:\n",
      "In practical settings, where models are applied to new data over time, simpler models (model6_fit) are often preferred for their better generalizability, ease of interpretation, and lower risk of overfitting, even if a more complex model might show better performance in-sample.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chat Summary\n",
    "\n",
    "chatlog_summary = {\n",
    "    \"1. Model Complexity and Generalizability\": \n",
    "        \"model7_fit is more complex with higher-order interactions but tends to overfit the training data, \"\n",
    "        \"leading to poorer out-of-sample performance. model6_fit, though simpler, generalizes better across different generations.\",\n",
    "    \n",
    "    \"2. In-sample vs Out-of-sample Performance\": \n",
    "        \"Both models show similar in-sample R-squared values, meaning they fit the training data similarly. \"\n",
    "        \"However, model7_fit shows a more significant drop in out-of-sample performance, indicating potential overfitting.\",\n",
    "    \n",
    "    \"3. Overfitting Concerns\":\n",
    "        \"The significant drop in out-of-sample performance for model7_fit when trained on specific generation data suggests it is overfitting the training data. \"\n",
    "        \"model6_fit, being simpler, shows better generalizability.\",\n",
    "    \n",
    "    \"4. Model Interpretability\":\n",
    "        \"model6_fit is simpler and easier to interpret. Complex models like model7_fit, with many interactions, can be harder to understand and explain.\",\n",
    "    \n",
    "    \"5. Real-world Considerations and Conclusion\": \n",
    "        \"In practical settings, where models are applied to new data over time, simpler models (model6_fit) are often preferred for their better generalizability, \"\n",
    "        \"ease of interpretation, and lower risk of overfitting, even if a more complex model might show better performance in-sample.\"\n",
    "}\n",
    "\n",
    "# Displaying the summary\n",
    "for topic, summary in chatlog_summary.items():\n",
    "    print(f\"{topic}:\\n{summary}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed5d1b4",
   "metadata": {},
   "source": [
    "link with ChatGPT: https://chatgpt.com/share/6736a05b-70c8-800d-8c62-34467b2706ca"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
